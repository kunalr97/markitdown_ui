AURORA

Agentic Unified Reasoning for Outcome-driven, Responsive and Accountable healthcare

Technical Description (Part B)

**List of participants**

|  |  |  |  |
| --- | --- | --- | --- |
| Participant No. | Participant organisation name | Short name | Country |
| 1 (Coordinator) | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Fraunhofer | DE |
| 2 | Barcelona Supercomputing Center | BSC | ES |
| 3 | Centre Hospitalier Universitaire de Liege | CHUL | BE |
| 4 | NTT Data Spain, S.L.U. | NTT DATA | ES |
| 5 | Heinrich-Heine-Universität Düsseldorf | UDUS | DE |
| 6 | Fundació Privada Institut d’Investigació Oncològica de Vall d’Hebron | VHIO | ES |
| 7 | Aarhus Universitet | AU | DK |
| 8 | Università di Pisa | UNIPI | IT |
| 9 | Goeteborgs Universitet | UGOT | SE |
| 10 | Trilateral Research IE | TRI | IE |
| 11 | Uniwersytet Jagiellonski | UJ | PL |
| 12 | empirica Gesellschaft für Kommunikations und Technologieforschung mbH | empirica | DE |
| 13 | RWTH Aachen University | RWTH | DE |
| 14 | Azienda Ospedaliera Universitaria Integrata Verona | AOUI VR | IT |
| 15 | Fundación Pública Andaluza Progreso y Salud M.P. | FPS | ES |
| 16 | Grupo SOLTI | SOLTI | ES |
| 17 | Fondatsiya LIBRe | LIBRe | BG |
| 18 | Universitatea de Medicina si Farmacie Iuliu Hatieganu Cluj-Napoca | UMF Cluj | RO |
| 19 | Kliniken Essen-Mitte Evang. Huyssens-Stiftung/Knappschaft gGmbH | KEM | DE |

# Excellence

Healthcare systems across Europe face challenges that are reshaping the delivery of care. Aging populations, rising chronic disease prevalence, workforce shortages, and escalating costs create an environment demanding innovative technological solutions. Simultaneously, healthcare organizations must deal with fragmented data landscapes, where valuable clinical information remains siloed across incompatible systems, limiting the potential for comprehensive patient understanding and evidence-based decision-making. These challenges are particularly acute in an era where healthcare professionals jointly navigate increasingly heterogeneous and distributed data sources –from multimodal imaging and genomics to real-time sensor data– while facing administrative burdens and time constraints.

Artificial Intelligence (AI) has emerged as a promising solution to address healthcare’s most pressing needs. Current AI applications in healthcare have demonstrated meaningful impact, particularly in radiology and digital pathology, where AI-assisted diagnostics show promise for improving diagnostic speed and accuracy across medical specialties. However, despite these early successes, the deployment of AI in healthcare remains fragmented and limited by **critical gaps** that prevent widespread adoption and optimal clinical utility, such as:

**Transition from Reactive Tools to Proactive Assistants**

Current healthcare AI operates as isolated, reactive tools lacking goal-oriented reasoning and adaptive capabilities needed for real clinical partnership [99]. While AI has shown success in specific applications like pancreatic lesion detection [40, 73] and prostate cancer grading [79], the transition to agentic AI that actively participates in healthcare delivery remains critical [49].

**Generative AI (****GenAI) Trust and Reliability**

GenAI unpredictability represents the main adoption barrier, with stakeholders struggling to determine when to trust AI outputs [33, 75]. AI "hallucinations" remain a critical concern, with studies showing popular GenAI chatbots making diagnostic errors 83% of the time in pediatric diseases [100]. Systematic reviews demonstrate that excessive trust in incorrect AI advice adversely impacts clinical accuracy [78],

**Multimodal Data Integration and Interoperability Challenges**

Data fragmentation is identified as a critical barrier by 61% of healthcare professionals, 62% of hospital representatives, and 71% of AI developers [75]. This study on AI deployment also emphasizes that interoperability challenges are compounded by the fragmented nature of hospital IT systems, even within the same institution. Healthcare's complexity demands AI systems capable of integrating diverse data modalities, but inconsistencies in data formats impede seamless integration [61, 83].

**Regulatory Compliance and Safety Frameworks**

Only 23% of hospital representatives feel prepared for EU AI Act obligations (AIA, [25]). The rapid evolution of GenAI models challenges traditional clinical evaluation and certification processes, necessitating new approaches to ensuring AI safety and efficacy [75]. Additionally, the introduction of the EHDS regulation will require adaptations across a variety of existing siloed health data systems to enable secondary use of health data.

**Human-AI Collaboration and Clinical Integration**

Despite technological advances, only 53% of U.S. consumers believe GenAI could improve healthcare, with limited meaningful adoption progress over the past year [19].

**AURORA Clinical Context**

The project concentrates on 3 medical fields: **Oncology** (**prostate cancer** [22, 44, 46, 80])**, Rheumatology (rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE)** [34, 60]) and **Periodontology** (**periodontitis** [10, 105]). A comprehensive analysis of current epidemiological data of those diseases based on recent European sources from 2020-2025 shows that these **conditions represent substantial public health challenges across the EU**, with periodontitis alone affecting approximately 60% of European adults. Europe bears a significant burden relative to its population size, with these diseases representing considerable healthcare costs and affecting predominantly older adults through different demographic patterns and risk profiles, reflecting the comprehensive healthcare provision in EU countries.

**Economic burden analyses** show that indirect costs from productivity losses substantially exceed direct healthcare expenditures, particularly for periodontitis and RA. For periodontitis, indirect costs amounted to 156 million € in Europe, while direct costs were “only” 2,520 million € in 2018. RA remains one of the costliest chronic diseases per patient across European studies, with indirect costs frequently equalling or exceeding direct medical costs [39]. The economic burden of prostate cancer in the EU was 8,430 million in 2009 according to [59], while [20] reported 470,000 new prostate cancer cases in Europe in 2020, representing 22% of all male cancers. Given that prostate cancer accounted for 23% of all new cancer cases in EU in men in 2020 and remains the most frequently occurring cancer in men, the economic burden has increased substantially over the decade.

**Demographic trends** indicate that population aging will substantially increase absolute disease burden over the next decades, even if age-standardized rates remain stable [34, 44, 105]. Prostate cancer cases are projected to increase from 1.4 million in 2020 to 2.9 million by 2040. Rheumatoid arthritis is expected to show an 80.2% increase between 2020 and 2050, affecting 31.7 million individuals worldwide by 2050. Periodontitis prevalence rises with age, with systematic reviews reporting 24% severe forms among European adults in high-income regions [95].

**Global health implications** extend beyond direct disease burden. Periodontal disease accounts for an estimated 3.5 million years lived with disability and results in an annual loss of $54,000 million in productivity globally [37]. These conditions demonstrate significant **systemic health connections**, with periodontitis and RA/SLE linked to cardiovascular disease, diabetes, etc., potentially amplifying their overall health and economic impact [94].

## Objectives and ambition

Our project addresses the critical gaps identified earlier within 3 medical fields. This is outlined with the ambition and objectives described in this section, which align closely with the scope of the call (section 2) and the key challenges in digital transformation, interoperability, and personalized care delivery within the European healthcare system. Our platform addresses the needs of the user groups described in the call: healthcare professionals, patients and healthcare systems while ensuring compliance with relevant regulations (such as GDPR [26], AIA [25] and MDR [24]) and incorporating robust cybersecurity measures to protect sensitive health data and maintain system integrity. We align as well with the European Health Data Space (EHDS) vision [23, 23, 43]: creating interoperable, multi-country solutions that improve patient treatments and health-system efficiency through data-driven innovation [15].

### Ambition and advances beyond the State-of-the-Art

We aim to a paradigm shift from conventional healthcare AI tools to intelligent, semi-autonomous agentic systems that can reason, plan, and execute complex clinical workflows while maintaining full regulatory compliance with European legislation. The project’s vision focuses on 5 innovative technological advances that address fundamental limitations in current healthcare AI applications.

#### Agentic architecture using the Model Context Protocol

AURORA’s most significant innovation lies in the development of **task-oriented AI agents** implemented using the recent Model Context Protocol (MCP) [3]. Unlike traditional healthcare AI systems that are isolated and reactive, we create specialized agents with distinct capabilities:

* **Regulatory and Compliance Agents** that continuously monitor adherence to EHDS, AIA, GDPR, and MDR requirements in real-time
* **Knowledge Agents** that maintain up-to-date medical knowledge bases and ensure information accuracy
* **Clinical Reasoning and AI Explainability Agents** that provide transparent, interpretable decision support with uncertainty quantification
* **Interoperability Agents** that seamlessly handle data format conversions and semantic mapping across healthcare data and terminology standards (e.g., HL7/FHIR, DICOM, SNOMED-CT, LOINC, ATC, etc.)
* **Language/Translation Agents** enabling multilingual support across European healthcare systems
* **User Interaction Agents** providing personalized interfaces for different stakeholder groups
* **Feedback/Learning Agents** that enable continuous system improvement through clinical validation

These agents are coordinated through **Orchestration Agents** and rule-based systems, creating *next-generation agentic AI systems* with advanced autonomy, adaptability, and probabilistic reasoning [47]. This approach directly addresses the critical gap identified by [76], which noted that current LLM-based systems in healthcare lack sophisticated multi-agent collaboration necessary for complex clinical workflows.

**Beyond State-of-the-Art**: Current healthcare AI applications require constant human intervention and operate as isolated tools. AURORA’s MCP-based architecture enables autonomous workflow orchestration where agents can initiate, manage, and complete complex clinical processes independently while maintaining continuous clinical oversight. This represents a fundamental advancement from reactive AI to proactive, goal-directed systems that can adapt dynamically to changing clinical contexts [38].

#### EHDS-Compliant Reference Architecture

AURORA will deliver a comprehensive **reference implementation** of an architecture fully compliant with the EHDS requirements [23], integrating all MCP components within a unified, secure framework. Our architecture builds upon previous developments of the project partners [12, 36] and the EHDS Regulation, incorporating advanced federated learning principles [77]. The architecture implements:

* **Semantic interoperability** through standardized terminologies and FAIR data principles
* **Privacy-preserving federated learning** mechanisms enabling cross-border collaboration without direct data sharing
* **Secure Processing Environments (SPEs)** with semi-automated compliance monitoring. We will extend already deployed blueprints architectures [18] with the additional requirements of the EHDS [36]
* **Dynamic consent management** supporting both primary and secondary use scenarios

**Beyond State-of-the-Art**: While current federated health systems focus primarily on data sharing protocols, AURORA creates an intelligent ecosystem where agentic AI systems can collaborate across institutional boundaries while maintaining data sovereignty. This extends recent work on federated EHRs [77] by adding autonomous reasoning capabilities.

#### Compliance-by-Design Framework with Enhanced Training Datasets

AURORA pioneers a **Compliance-by-Design Framework** that transforms how AI systems are developed for healthcare. Using retrospective datasets from clinical partners combined with openly available medical data, we will create training datasets that are modified through interaction with our agentic framework. This approach ensures regulatory compliance embedded at the data level rather than retrofitted post-development. It incorporates:

* **AIA-compliance and risk assessment methodologies** integrated into the training pipeline
* **GDPR-by-design data processing** with comprehensive privacy impact assessments
* **MDR alignment** for Software as Medical Device (SaMD) classification and validation
* **Dynamic bias monitoring** through continuous agent oversight during training and deployment

**Beyond State-of-the-Art**: Current approaches to healthcare AI regulation involve post-hoc compliance checking. AURORA’s framework embeds regulatory requirements directly into the training data (and model architecture), creating compliant AI systems. This proactive approach significantly reduces regulatory risk and accelerates the path to clinical deployment.

#### Multi-Scale Foundation Model Ecosystem

AURORA will develop and evaluate multiple **foundation models of varying sizes** specifically fine-tuned for our clinical contexts using our enhanced multimodal datasets. Specific requirements and evaluation results of our VAs will guide the selection and optimization of these models, enabling matched model deployment for different clinical contexts and computational constraints. Our approach includes:

* **Multimodal integration** of EHRs, medical imaging, genomics, proteomics, patient-reported outcomes, etc.
* **Federated fine-tuning protocols** that preserve data privacy while improving model performance
* **Uncertainty quantification** and confidence calibration for clinical decision support
* **Multilingual capabilities** across a set of European languages with medical terminology preservation
* **Efficient model scaling** from edge deployment to high-performance computing environments

**Beyond State-of-the-Art**: Current healthcare foundation models are typically developed in isolation from regulatory frameworks and clinical workflows. AURORA’s approach integrates foundation model development directly with an agentic architecture and regulatory compliance, creating a generation of deployable healthcare AI foundations models that meet European regulatory standards.

#### Clinical Virtual Assistants with Human-in-the-Loop Validation

The project will deliver **validated VAs** for three high-impact clinical use cases (prostate cancer, RA/SLE, and periodontitis) that demonstrate statistically significant improvements over standard of care. These assistants represent the practical implementation of our agentic architecture in real clinical environments. Key innovations include:

* **Human-in-the-loop validation** integrated throughout all development and deployment phases
* **Connection to our agentic architecture** supporting RAG [32] capabilities to ensure not only knowledge access, but also regulatory compliance and explainability feedback
* **Real-time clinical decision support** with explainable AI mechanisms
* **Adaptive learning systems** that improve through clinical feedback
* **Multi-stakeholder interfaces** serving both clinicians and patients

**Beyond State-of-the-Art**: Current virtual health assistants operate primarily as information retrieval systems with limited reasoning capabilities. AURORA’s assistants represent autonomous clinical teammates capable of complex reasoning, planning, and execution while maintaining transparent decision-making processes and continuous learning capabilities [107].

### AURORA objectives

**Dissemination, exploitation, communication and outreach objectives** and KPIs are defined in section 2.2.

#### Objective 1 (O1): Development of an EHDS-compliant Federated Multi-site Agentic Architecture

**Description**: Development of an agentic reference architecture with corresponding implementation that extends previous developments from some partners [12, 36], enabling integration of multimodal data sources distributed across multiple clinical environments, incorporating EHDS requirements and ensuring GDPR, MDR and AIA compliance.

| KPIs | Target | Measurement Method | WP/Deliv. |
| --- | --- | --- | --- |
| Cross-site federated integration | Successfully integrate ≥6 hospital sites across ≥5 EU countries | System integration tests |  |
| EHDS compliance rate | ≥85% compliance with EHDS APIs, metadata and standards | Compliance audit reports |  |
| GDPR/MDR/AIA compliance audits passed | ≥85% pass rate on all compliance audits (mandatory and recommended) | Audit reports |  |
| System performance | Mean response time <2 seconds for 1000 concurrent users | Performance testing tools |  |
| Architecture reusability | ≥60% of modules derived from previous projects | Architecture documentation review |  |
| Security compliance level | ISO 27001 or equivalent security across all sites | Security audit |  |
| Federated learning capability | Successful implementation across all sites | Technical demonstration |  |

**Relevance to Call:** Directly addresses the requirement for leveraging *extensive and diverse multimodal health and research data* and developing solutions in *multinational consortia* with *federated governance approaches*”

#### Objective 2 (O2): Development of Open Multilingual, Multi-Scale GenAI Models

**Description**: Develop, fine-tune, validate and compare multiple open (foundation) GenAI models of varying scales, augmented by specialized AI tools (RAG systems, knowledge graphs, clinical decision support algorithms), trained on multimodal data in multiple EU languages for 3 clinical clusters. These models will be trained and augmented both on multimodal retrospective data, data from public repositories and on data generated within the project.

| KPIs | Target | Measurement Method | WP/Deliv. |
| --- | --- | --- | --- |
| Model diversity | ≥4 foundation models fine-tuned (including at least 2 EU-developed models) | Model registry documentation |  |
| Language coverage | Support for ≥4 EU languages with <5% variance performance | Language-specific benchmarks |  |
| Multimodal training data | Integration of ≥5 data modalities per model | Training data documentation |  |
| Model explainability score | ≥80% explainability scores | Explainability using SHAP/LIME methods |  |
| Trustworthiness score | ≥4.0/5.0 average trustworthiness rating | ALTAI assessment framework |  |
| Bias mitigation effectiveness | <5% performance variance across demographic groups | Fairness evaluation metrics |  |
| Number of agentic components used | ≥ 8 agents used in annotation, training and operation of the models | Agent count |  |
| Model size optimization | At least 3 model sizes (small: <3B, medium: 3-10B, large: >10B parameters) | Model specifications |  |
| Open-source contribution | ≥80% of non-sensitive models released as open source | Repository records |  |

**Relevance to Call:** Directly addresses the requirement for *new or optimised trustworthy and ethical GenAI models* with emphasis on EU-developed solutions and open-source approaches.

#### Objective 3 (O3): Implementation of Comprehensive Healthcare Data and Terminology Standards

**Description**: Design and implement components supporting international healthcare data standards (HL7/FHIR) and standard terminologies (SNOMED-CT, LOINC, ATC, ICD-10/11, …) to ensure semantic interoperability across EU healthcare systems.

| KPIs | Target | Measurement Method | WP/Deliv. |
| --- | --- | --- | --- |
| FAIR data principles adherence | ≥85% of data sources meeting FAIR criteria | FAIR assessment checklist |  |
| Standards coverage | Implementation of ≥6 international standards/terminologies | Technical documentation |  |
| Interoperability validation | 100% pass rate on HL7 FHIR and terminologies conformance tests | Automated testing suite |  |
| Cross-border data exchange | Successful data exchange with ≥3 different national health systems | Integration testing |  |
| Terminology mapping accuracy | ≥85% accuracy in cross-terminology mappings | Expert validation |  |
| API compliance | Full compliance with EHDS API specs. | Compliance testing |  |

**Relevance to Call:** Ensures *cross-country applicable methodologies* and supports EHDS infrastructure requirements.

#### Objective 4 (O4): Clinical Virtual Assistant Solutions

**Description**: Deliver scalable, user-centred Virtual Assistant (VAs) modules for 3 medical fields that will provide personalized diagnostic support and care recommendations while ensuring clinical safety and user trust.

| KPIs | Target | Measurement Method | WP/Deliv. |
| --- | --- | --- | --- |
| Number of virtual assistant modules | ≥ 6 of virtual assistant modules delivered | Prototypes |  |
| Clinical decision accuracy | ≥85% concordance with clinical guidelines or other relevant criteria | Clinical studies |  |
| Personalization effectiveness | ≥80% of recommendations rated as appropriately personalized | Clinical expert review panels |  |
| User satisfaction score | SUS score ≥75; UEQ score ≥4.0 | Standardized usability testing |  |
| User adoption rate | ≥70% of trained healthcare professionals actively using the system in the project | Usage analytics |  |
| Patient satisfaction score (when applicable) | ≥4.0/5 average (Likert) | Questionnaire to the patients[[1]](#footnote-2) |  |
| Response time | <15 seconds for 85% of queries | System monitoring |  |
| Human-in-the loop validation and assessment | Positive evaluation by more of 80% of the 5 dimensions by at least 6 clinicians in each participating clinical site | Validation and assessment for model attributes (framework based on QUEST [91]) |  |
| Safety event rate | Zero critical safety events attributable to AI recommendations | Clinical incident reporting, report on near-miss events |  |
| Multimodal data integration | Successfully integrate ≥3 data types per use case | Integration testing |  |
| Technical scalability | Support ≥50 concurrent users per each virtual assistant platform | Resource utilization monitoring |  |
| Clinical workflow integration | ≥80% of users report sufficient potential for improved workflow efficiency in real world settings | User surveys |  |

**Relevance to Call:** Demonstrates *added value and clinical utility* in *different medical fields*.

#### Objective 5 (O5): Clinical Validation and Safety Demonstration

**Description**: Demonstrate clinical utility, diagnostic accuracy, and safety through rigorous clinical validation studies comparing AI-assisted care with standard of care, while ensuring full compliance with EU Trustworthy AI guidelines.

| KPIs | Target | Measurement Method | WP/Deliv. |
| --- | --- | --- | --- |
| Clinical utility improvement | 80% improvement in diagnostic efficiency vs. standard of care, if applicable to the use case | Clinical studies; clinical utility methods (e.g., [11]) |  |
| Diagnostic sensitivity for primary endpoint | ≥80% for primary conditions | ROC analysis |  |
| Diagnostic specificity for primary endpoint | ≥80% for primary conditions | ROC and AUC analysis of AI components |  |
| No. of safety incidents during validation | <5 minor incidents, 0 major incidents | Safet**y** monitoring reports |  |
| Patient safety metrics | 80% compliance with ISO 14155 | Safety audit reports |  |
| Trustworthy AI compliance | 90% compliance with all 7 EU Trustworthy AI requirements | ALTAI assessment |  |
| Clinical confidence score | ≥4.0 average clinician confidence rating | Questionnaires |  |

**Relevance to Call**: Addresses the requirement to *assess the relative effectiveness of the solutions compared with standard of care* and demonstrate *technical robustness, healthcare utility and trustworthiness*.

#### Objective 6 (O6): Regulatory Preparedness and Market Readiness

**Description**: Establish a comprehensive regulatory strategy and demonstrate regulatory readiness for all developed components, including preparation for GDPR/MDR/AIA compliance and Health Technology Assessment within the constraints of the resources of the project.

|  |  |  |  |
| --- | --- | --- | --- |
| KPIs | Target | Measurement Method | WP/Deliv. |
| Regulatory strategy completeness | 100% of components with documented regulatory pathway | Regulatory documentation |  |
| EHDS/GDPR/MDR/AIA gap analysis/ compliance rate | Gap analysis completed for all applicable components; ≥80% compliance with applicable requirements | Gap analysis reports; Compliance assessment |  |
| Regulatory interactions | ≥2 formal meetings with notified bodies/competent authorities | Meeting minutes |  |
| HTA preparedness | HTA1 ≥70% by M12; ≥95% by M36 | Review of endpoint specification templates |  |
| HTA2 ≥80% by M18; ≥95% by M36 | Audit of HTA checklist completion across pilots; |  |
| HTA3 delivered and approved by the Steering Committee (on time). | Delivery of packages |  |
| Risk management completion | ISO 14971 compliant risk analysis for all components | Risk management files |  |
| Post-market surveillance plan | Comprehensive plan developed and validated | Regulatory review |  |

**Relevance to Call**: Directly addresses the requirement to *develop a regulatory strategy/interaction plan with regulators* including HTA considerations.

### Technology Readiness Level Progression

AURORA targets a TRL progression that reflects the ambitious yet achievable nature of the project:

* **Starting TRL (3-5)**: We start with validated individual components (MCP framework, federated learning protocols, foundation models) that have been demonstrated in laboratory and limited clinical environments. We build on earlier developments by partners, e.g. prototypes of EHDS-compliant architectures [36] or fine-tuned modelling approaches for foundation models processing legacy medical records [35].
* **Target TRL (6-7)**: By project completion, AURORA will achieve:
  + **TRL 6**: Fully functional prototypes of the agentic architecture demonstrated in relevant clinical environments with all major components integrated
  + **TRL 7**: System-level demonstrations in operational clinical environments with validation of safety, efficacy, and regulatory compliance across multiple sites

This progression is supported by our comprehensive validation methodology, which includes: **Technical validation** of all agentic components and their interactions; **Clinical validation** through controlled trials in three distinct use cases; **Regulatory validation** through engagement with competent authorities and compliance auditing; and **User validation** through co-design processes with clinical partners and patient representatives

AURORA’s ambition extends beyond technical innovation to create sustainable transformation in EU’s healthcare delivery. The project establishes a foundation for prototyping and scaling across healthcare systems through:

* Open-source implementations of core agentic components using established frameworks
* Standardized APIs enabling integration with existing healthcare IT infrastructures
* Comprehensive documentation and training materials supporting adoption
* Regulatory pathway templates accelerating approval processes for similar systems
* Evidence generation frameworks enabling continuous real-world validation

## Methodology

Our methodology provides a sound approach to create VAs in **3 medical fields**: **Rheumatology**, **Oncology** and **Periodontology**. The models to be used by these VAs will be trained by **retrospective data** facilitated by the participant institutions, complemented with **openly available datasets**, **validated guidelines and best practices** documents. Detailed information about all clinical studies and available data can be found in the appendices.

**Rheumatology (RA/SLE) use cases**

The project will develop 2 VAs, one targeted to patients and the other one to HCPs. Each of these VAs will have two versions, one for RA patients and another one for SLE patients.

**HCPs**: the project will develop two major components for this user group. First, we will develop, building upon recent prototyping work of one of the partners, a VA with a pipeline preprocessing multimodal data (images, disclosure reports, lab reports, etc.) from patient’s medical record, together with up-to-date information from other clinics brought to the clinicians by the outpatients, into structured information that can be presented to the HCPs. A second VA will collect this information, together with the information facilitated by the patients, and suggest a care plan that matches the evolution of the patient. The clinician will evaluate this suggestion and modify it or reject it according to her experience. If appropriate, the next steps will be discussed with the patient and sent to her application for further monitoring.

**Patients**: a VA will be developed where each patient, through validated questionnaires (PROMs), can report information about disease symptoms, disease burden (e.g., quality of life data, sleep problems, fatigue), treatment adverse events, and treatment adherence. The patient will obtain access to clear & customized views of their care plan in a transparent manner and flare risks. The VA will also provide the rationale of the therapy and provide tailored educational materials, adapted through different AI agents.

**Oncology (prostate cancer) use cases**

Within this medical field we address 2 use cases: development of AI prognostic models for supporting treatment decisions in first-line prostate cancer therapy, and the creation of a VA for trial matching and Molecular Tumor Board (MTB) support, aiming to prioritize clinical trial options for late-stage patients based on clinical and molecular profiles. These VAs are targeted to **HCPs**, although the second one may provide supervised input to patients.

*Prognostic models for prostate cancer care*

This VA integrates prognostic models to support prostate cancer care. It will extract structured information from clinical texts, and pathology and imaging reports (CT, MRI, bone scans), complemented with genomic data from patients with newly diagnosed metastatic disease. In this disease setting, treatment options include a range of combination therapies (“intensified” vs “de-intensified” treatment) but clinicians lack robust tools for decisions at individual patient level. The VA will be built and validated with datasets from VHIO (creation/development) and AOUI VR (external validation). They will focus on predicting overall survival (OS) at the time of first line of metastatic prostate cancer treatment, providing clinicians with robust, evidence-based support tools to recommend intensified vs de-intensified treatment for individual patients. We anticipate that the VA can optimize treatment selection, avoid over-treatment and toxicities in patients who may not need intensified treatment, and facilitate harmonise implementation of clinical guidelines in a complex patient care setting. A proof-of-concept VA will also be developed to facilitate consultations and patient-physician communication, integrating the models’ predictions into clinical workflows.

*VA for MTB report generation and trial matching*

The second VA is designed to assist in MTB report generation and clinical trial matching. Molecularly directed clinical trials represent an opportunity to accelerate drug development but also an opportunity for patients with late-stage (those where several treatments have failed to them, and survival expectation is very poor) to receive a potentially benefiting therapy. However, there is significant disparity among healthcare systems/centers when it comes to access to clinical trials for patients. By incorporating genomic and clinical information, the VA will analyze data using established knowledge bases (OncoKB, ClinVar, COSMIC) to generate recommendations comparable to a MTB, including curated trial suggestions. Data sources will include Spanish clinical trials, with international expansion supported by the internal clinical trials database from VHIO, encompassing over 300 trials with curated molecular criteria. Validation will be conducted on the HOPE cohort (240 cases with genomic results, where a MTB already issued an expert recommendation report) and expanded in the HOPE2 prospective trial with 100 new cases where the report from AI vs human experts will be compared. The outcome will be the automated generation of expert-like reports and enhanced trial enrolment recommendations, accelerating and optimizing patient access to suitable treatments.

**Periodontology (periodontitis and peri-implantitis) use cases**

Within this medical field we will address 2 use cases and develop VAs addressing the full continuum of periodontal and peri-implant care. For periodontitis the VAs will focus on controlled screening, chairside diagnosis, prediction of treatment response and personalization of supportive therapy intervals, and for peri-implantitis they will focus on risk assessment for peri-implant diseases, and AI-assisted peri-implant diagnostics.

*Periodontitis*

The project will develop VAs targeted to patients and to HCPs.

**Patients**: within a controlled environment at the participating institutions, patients will use a dedicated application to capture standardized photographs of their teeth and complete a series of questionnaires (PROMs). The application will generate a preliminary screening report with follow-up advice in case periodontitis is suspected. It will also support patients during treatment by documenting progress and providing tailored educational and advisory materials.

**HCPs**: Clinicians will use VAs to predict treatment response and personalize supportive periodontal therapy intervals. They will evaluate this input and provide information for the training and adjustment of the VAs. If appropriate, the next steps will be discussed with the patient and sent to her application for further monitoring. Diagnostic evaluation will be performed by the clinician and collected prospectively to train and validate the diagnostic VA.

*Peri-Implantitis*

The project will develop VAs targeted to **HCPs**. Clinicians will use the VAs to assess the risk of developing peri-implant diseases and to support diagnostic evaluations around dental implants. The VAs will integrate clinical, radiographic, and patient-reported data to generate individualized risk profiles and diagnostic suggestions. Clinicians will validate AI outputs, provide feedback for iterative refinement, and use the tools to guide treatment planning and long-term monitoring.

### Agentic Architecture for Virtual Assistants

We propose an innovative **Agentic Architecture** to support VAs operation in healthcare environments. Unlike conventional AI systems that respond to prompts or generate content, our architecture will employ AI agents capable of goal-directed reasoning, planning, and execution within predefined clinical guardrails [49]. Each agent will maintain specific expertise while contributing to a unified clinical decision-making process or to implement some governance restrictions [14].

The architecture is built upon the **Model Context Protocol (MCP**, Anthropic 2024 [3]). MCP is an open-source standard enabling seamless integration between AI-applications and external data sources and tools. MCP addresses the N×M integration problem in AI development, where each AI application required custom integrations with external services. MCP operates on a client-host-server pattern using JSON-RPC 2.0 specification. Hosts are LLM applications, clients are protocol connectors maintaining server relationships, and servers are lightweight programs exposing specific capabilities through standard interfaces. Rather than requiring custom API integrations for each AI tool combination, MCP provides a unified protocol enabling AI application to interact with any MCP server, reducing integration complexity and enabling an ecosystem reuse across platforms. Our architecture is divided in 5 layers:

* **Layer 0: Architecture Core** – Agents that form the backbone of the architecture, enabling coordination, reasoning, and interoperability.
* **Layer 1: Data Interoperability and Compliance Agents** – Foundation layer ensuring privacy, data quality, and audit capabilities for healthcare data processing.
* **Layer 2: Training Oversight Agents** – Agents focused on ensuring compliance during model training and data processing phases.
* **Layer 3: Model Validation Agents** – Agents responsible for validating model outputs, explainability, and regulatory compliance before deployment.
* **Layer 4: Runtime Monitoring Agents** – Real-time monitoring agents that ensure ongoing compliance and safety during system operation.

The following table consolidates the agent architecture from section 1.1.1 with our implementation layers.

XXX CHECK

| Agent Category | Agent Name | Function & Regulatory Focus | Implementation Phase |
| --- | --- | --- | --- |
| **Orchestration** | Orchestration Agents | Coordinate workflows and manage inter-agent communication for autonomous task management | Architecture Core |
| **Compliance & Regulatory** | Regulatory and Compliance Agents | Monitor adherence to EHDS, AIA, GDPR and MDR requirements | Runtime Core  Model Validation |
|  | Compliance Reporting Agent | Generate automated audit reports for regulators and compliance documentation | Runtime Monitoring |
| **Privacy & Security** | De-identification Agent | Remove/transform sensitive medical identifiers in patient records and clinical notes | Data Compliance |
|  | Privacy and PII/PHI Detection Agent | Prevent PII/PHI transmission to unsecured endpoints for GDPR violation prevention | Runtime Monitoring |
| **Data Management** | Data Quality Agent | Validate medical data accuracy and completeness for clinical documentation integrity | Data Compliance |
|  | Data Standards Validation Agent | Validate FHIR compliance and HL7 standards for FHIR/DICOM interoperability | Training Oversight |
|  | Audit Trail Agent | Maintain compliance documentation for regulatory reporting requirements | Data Compliance |
| **Knowledge & Terminology** | Knowledge Agents | Maintain up-to-date medical knowledge bases ensuring information accuracy | Architecture Core |
|  | Terminology Compliance Agent | Ensure accuracy in data transformation/exchange using ICD-10/11, SNOMED CT, LOINC, … | Training Oversight |
| **Clinical Reasoning** | Clinical Reasoning and AI Explainability Agents | Provide transparent, interpretable decision support with uncertainty quantification | Architecture Core |
|  | Explainability Agent | Generate human-level explanations for clinical reasoning transparency | Model Validation |
|  | Clinical Accuracy Agent | Ensure correct terminology codes retention for medical coding accuracy | Model Validation |
| **Interoperability** | Interoperability Agents | Handle data format conversions and semantic mapping across HL7/FHIR, DICOM, SNOMED-CT, LOINC, ATC | Architecture Core |
| **User Interface** | User Interaction Agents | Provide personalized interfaces for different stakeholder groups | Architecture Core |
|  | Language/Translation Agents | Enable multilingual support across European healthcare systems | Architecture Core |
| **Quality & Safety** | Safety Verification Agent | Prevent harmful medical recommendations following patient safety protocols | Model Validation |
|  | Response Validation Agent | Validate clinical output accuracy for medical recommendation safety | Runtime Monitoring |
|  | Error Correction Agent | Correct medical inaccuracies in responses through clinical error mitigation | Runtime Monitoring |
| **Learning & Monitoring** | Feedback/Learning Agents | Enable continuous system improvement through clinical validation feedback | Architecture Core |
|  | Bias Monitoring Agent | Detect and mitigate healthcare disparities for clinical decision fairness | Training Oversight |
|  | Performance Tracking Agent | Monitor training metrics for clinical accuracy against medical benchmarks | Training Oversight |

![](data:image/png;base64...)

Figure 1. Overview of the AURORA architectural components, including some basic workflow interactions.

The architecture is designed to comply with the **EHDS requirements** and the **International Data Spaces Reference Architecture Model** ([IDS-RAM](https://internationaldataspaces.org/wp-content/uploads/IDS-Reference-Architecture-Model-3.0-2019.pdf)). Drawing from recent advances in health data spaces [48], our system implements a decentralized, federated architecture that enables secure data sharing while maintaining individual data sovereignty:

* **EHDS compliance features**: Semantic interoperability through HL7/FHIR data model and standardized terminologies (SNOMED, LOINC, ICD, ATC); Privacy-preserving federated learning mechanisms that enable cross-border collaboration without direct data different sharing [69]; FAIR data principles implementation; and patient-controlled access mechanisms aligned with GDPR requirements.
* **IDS-RAM integration**: Trust and security framework with identity management and access control; Data sovereignty connectors enabling secure data exchange between institutions; Usage control and provenance tracking for data interactions; Standardized APIs for seamless integration with existing IT infrastructures.

Our architecture builds upon previous developments of some partners [12, 36] and introduces several innovations that significantly advance the current state-of-the-art in healthcare AI systems:

* **Semi-autonomous Clinical Workflow Management**: Traditional healthcare AI systems require constant human intervention and operate as isolated tools. Our agentic architecture implements semi-autonomous workflow orchestration where agents can initiate, manage, and complete complex clinical processes independently. For instance, the system could autonomously coordinate clinical data analysis, imaging analysis, biomarker interpretation, and treatment planning while maintaining continuous clinical oversight [31, 52]. The oversight mechanisms are based in our HITL framework (section 1.2.4).
* **Dynamic Multi-Modal Data Fusion**: Building upon recent advances in medical cognitive agents [65], our architecture will allow secure and privacy compliant access to real-time, context-aware data from EHRs, medical imaging, genomics, proteomics, and patient-reported outcomes. The system will compare different advanced reasoning frameworks that can synthesize heterogeneous data types to generate comprehensive clinical insights and select the most appropriate for the task [71, 99].
* **Explainable Agentic Decision-Making**: Addressing the critical need for transparency in medical AI [85], our architecture will incorporate built-in explainability mechanisms at the agent level. Each agent maintains detailed reasoning traces, uncertainty quantification, and bias monitoring capabilities, ensuring that clinical recommendations are interpretable and trustworthy [14].
* **Adaptive Learning and Personalization**: The architecture implements hierarchical reinforcement learning mechanisms that enable continuous adaptation to individual clinical contexts [71]. Unlike static AI models, our agents will learn from clinical outcomes and refine their decision-making processes, leading to increasingly personalized and effective care recommendations.

#### Secure Processing Environments

**Secure Processing Environments (SPEs)** are controlled, identity-bound workspaces in which sensitive health data are analysed *in situ*, with strict logging and output controls. The EHDS anchors this model by requiring that secondary use of health data occur only via a SPE, with exports limited to non-personal, disclosure-checked outputs [27]. We will use this concept, not for this secondary use, but to design our **Federation Services**, following a layering approach as designed in the architectural blueprint of [18], separating **infrastructure, data, and organizations**. This will allow us to explicitly define governance and data privacy requirements, minimizing the data movements and enabling auditable workflows. This approach is in line with recent analyses call for clearer harmonisation of minimum controls and for common patterns tailored to modern analytics. Our concept will extend our previous developments [36] by including an agentic approach as workflow controllers within the SPE.

### Foundation models

Foundation models have become the leading approach in AI, revolutionizing the way machine learning is applied across various fields. They are “*… large-scale models trained on broad data at scale that are adaptable to a wide range of downstream tasks*” [8] and mark a shift from specialized models to versatile, general-purpose architectures. Our focus is on **open-source models** that can be refined according to our requirements, such as [IBM’s Granite](https://www.ibm.com/granite), [Meta’s Llama](https://www.llama.com/), [Google’s Gemma](https://deepmind.google/models/gemma/), [OpenAI gpt-oss](https://openai.com/open-models/), [OpenGPT-X’s Teuken 7B](https://opengpt-x.de/models/teuken-7b-de/), [Mistral AI](https://mistral.ai/), [Alibaba Cloud’s Qwen](https://qwen.ai/), etc. All these models offer versions of different sizes and support the possibility of integration multimodal data, which fits within our goal of testing and optimising size and performance. Special attention will be given to compliance aspects of the models related to explainability, and categorisation related to the AIA.

Although generic models encode also medical knowledge [84], **healthcare foundation models** show significant promise by enabling more efficient data interpretation, clinical summarization, and decision support. In the literature there are more than 50 examples of specific healthcare foundation models. The landscape shows remarkable diversity in model architectures, from BERT-based clinical language models to Vision Transformers (ViTs) for medical imaging and novel molecular graph neural networks for drug discovery. The most frequent type are clinical natural language processing foundation models. ClinicalBERT family leads the clinical NLP landscape through multiple specialized variants [2, 96]. GatorTron [102] have demonstrated strong performance in answering medical questions, generating discharge summaries, suggesting diagnoses or treatment plans, and supporting documentation workflows. Foundation models trained on scientific literature demonstrate exceptional performance on biomedical knowledge tasks, with several models achieving state-of-the-art results across comprehensive benchmarks. BioBERT [50] established the foundation for biomedical language modelling trained on PubMed abstracts and PMC articles.

Regarding **multimodal healthcare foundation models**, based upon Vision Language Models (VLMs), there are examples such as LLaVA-Med (Microsoft, [51]), or the most recent MedGemma (Google, [81]), which is based upon the Gemma multimodal models. As an example, MedGemma achieves 2.6-10% improvements on medical multimodal question answering, 15.5-18.1% improvements on chest X-ray finding classification, and 10.8% improvement on agentic evaluations compared to the base models. This field is in constant evolution, and we will follow up and benchmark the most recent advances in this area (see, e.g., [53]).

#### Optimisation with Comprehensive Validation

This methodological component creates trustworthy AI foundations through systematic model fine-tuning and validation protocols that exceed current state-of-the-art standards.

**Multi-Modal Fine-Tuning Protocol**: We implement a systematic comparison of state-of-the-art foundation models using curated datasets from clinical partners. Fine-tuning employs agentic-based Retrieval-Augmented Generation (RAG), with validated medical knowledge graphs to prevent hallucinations and ensure clinical accuracy. We will integrate Uncertainty Quantification using recent approaches [56] to provide confidence intervals for AI outputs.

**Bias Detection and Fairness Evaluation**: Continuous bias monitoring will employ frameworks such as [Fairlearn](https://fairlearn.org/) and [AI Fairness 360](https://ai-fairness-360.org/), measuring performance across demographic groups (age, gender, ethnicity, socioeconomic status) using metrics including statistical parity, equalized odds, and calibration. We will implement adversarial debiasing techniques and demographic-aware data augmentation strategies to ensure equitable performance across diverse patient populations.

**Robustness and Safety Assessment:** Robustness evaluation follows the NIST AI Risk Management Framework (AI RMF 1.0 [90]) methodology for trustworthiness in AI systems, systematically testing model performance under adversarial conditions, prompt injection attacks, and emergent security risks as outlined in formal frameworks for assessing security risks in GenAI models [86]. Safety assessment employs the QUEST framework's comprehensive evaluation principles including Quality of information, Understanding and reasoning, Expression style and persona, Safety and harm, and Trust and confidence [91], incorporating TrustLLM benchmark evaluations across truthfulness, safety, fairness, robustness, privacy, and machine ethics dimensions [41] for systematic evaluation of potential risks, inappropriate recommendations, and hallucination detection using established clinical benchmarks.

### Conversational AI and Virtual Assistants

Conversational AI is reshaping human-computer interaction by enabling users to engage with digital systems through natural language [54, 106]. Within healthcare contexts, conversational AI presents opportunities for enhancing patient engagement and clinical workflows [67], functioning as symptom assessment tools while providing personalized health education and medication adherence support [16].

Modern VAs support multiple input modalities to optimize accessibility and user engagement [93]. Advanced automatic speech recognition systems, integrated with sophisticated NLP pipelines, process spoken language accurately across diverse accents, languages, and acoustic environments [101]. This multimodal integration enables seamless transitions between communication channels based on user preferences and situational requirements [89]. Despite these advances, current systems face persistent challenges including hallucination, limited long-term contextual memory, insufficient multimodal fusion mechanisms, and lack of transparent reliability assessment [103].

Based upon the architecture proposed in previous sections, we will address these limitations through intelligent orchestration of specialized conversational AI modules, such text-based chatbots, voice assistants, etc. The project will test and evaluate different **Confidence Calibration** methods that are appropriate to our healthcare environment.

### Human-in-the-Loop (HITL) Validation

Our validation framework implements structured clinician assessment protocols that ensure clinical relevance, safety, and usability while building evidence for regulatory approval.

**Multi-Phase Clinical Validation**: Following the DECIDE-AI guidelines [98], we implement a 3-phase validation approach: (1) Expert review phase with structured evaluation by medical experts using validated assessment instruments measuring clinical accuracy, appropriateness, and safety; (2) Simulated clinical environment testing using standardized patient scenarios with think-aloud protocols to assess decision-making processes; and (3) Real-world pilot validation in controlled clinical settings with comprehensive outcome measurement.

**Trust Calibration and Human Factors Assessment**: Trust calibration employs Bayesian-based collaboration models measuring AI influence on clinical decisions, diagnostic accuracy improvement, and appropriate reliance patterns. Human factors evaluation uses the validated System Usability Scale (SUS) complemented by structured interviews exploring workflow integration challenges and acceptance factors.

**Clinical Performance Metrics**: Primary clinical endpoints include diagnostic accuracy improvement (sensitivity, specificity, positive/negative predictive values), time-to-diagnosis reduction, clinical workflow efficiency gains, and patient safety indicators. Secondary endpoints assess clinician satisfaction, usability, and long-term adoption patterns.

### Clinical Integration

We will implement and test integration into clinical workflows while maintaining regulatory compliance and evidence generation for broader adoption.

**Clinical Workflow Integration**: Deployment methodology follows the SALIENT framework [97] across these stages: system preparation with technical infrastructure validation, algorithm validation in clinical context, leadership engagement ensuring organizational readiness, gradual rollout, evaluation with continuous monitoring, new knowledge integration, and transformation assessment measuring organizational impact.

**Regulatory Engagement Strategy**: Proactive engagement with competent national authorities through regulatory sandbox participation where available.

### Gender Dimension

AURORA systematically integrates sex and gender analysis throughout its research methodology, recognizing that biological sex and social gender factors significantly influence healthcare AI performance and acceptance.

**Methodological Integration**

*Data and Algorithm Assessment*: The project conducts systematic evaluation of training data demographics ensuring balanced representation across sex and gender categories. All AI models undergo sex-stratified and gender-stratified performance evaluation with bias detection targeting sex/gender-based algorithmic discrimination. Mitigation strategies include demographic-aware training and post-processing fairness corrections.

*Clinical Implementation*: Use case validation protocols examine differential performance across sex and gender categories, acknowledging that biological sex (male/female, based on physiology) may differ from gender identity (man, woman, transgender, nonbinary). Both dimensions influence health outcomes and healthcare experiences. The BSC [BioInfo4Women](https://bioinfo4women.bsc.es/) group provides specialized gender-conscious research expertise. Workflow assessments consider gender-specific healthcare delivery patterns and differential impacts on providers.

**Clinical Context**

Selected clinical use cases reflect gender-specific disease patterns (rheumatoid arthritis with female prevalence, prostate cancer affecting only men) while ensuring developed approaches remain extensible to other morbidities. This validates gender-responsive AI while maintaining broad applicability.

**Organizational Commitment**

The consortium's gender strategy recognizes biological sex and gender identity as sources of added value for excellence, creativity, and societal relevance. Partner organizations implement **Gender Equality Plans** with women in key WP and task leadership roles. The project ensures gender-neutral language, avoids stereotyping, encourages women's participation in R&D&I activities, and respects transgender and nonbinary perspectives. The project addresses systemic barriers enabling equal access to project benefits while fostering stakeholder diversity across all gender categories throughout project phases.

### Open Science

The consortium will follow the Open Science policy of Horizon Europe as detailed in the General Model Grant Agreement (Art. 17). The consortium will establish an appropriate strategy considering lawfulness, transparency, integrity, interoperability, reuse of data, intellectual property rights, licensing agreements and being trustworthy in developing, undertaking, reviewing, reporting and communicating project outcomes. The strategy builds on the guidelines set out by the European Open Science Cloud (EOSC). Although some deliverables are classified as sensitive, the approach of the consortium is to publish the technical and clinical results in open access publications on Zenodo and arXiv. The consortium will also aim to publish AI models, interfaces and datasets as open source (e.g., on GitHub, HuggingFace).

### Data Management

The consortiumaims to improve and maximize access to and re-use of scientific data, i.e., training data sets, fine-tuned models, scientific reports, etc. To guarantee correct protection and access to the above data, the project will put in place the required data management structure and define a **Data Management Plan (DMP)** to govern the processing, storage, sharing, preservation, and archiving of data. The management of open data will be based on the resources needed to make research data quality-controlled, FAIR-compliant and as open as possible. The DMP will adhere to the relevant guidelines and regulations such as GDPR [26] and the main FAIR principles:

* **Findability**: All data will be registered with community accepted metadata and unique identifiers for all units of stored information. Publishing of data will be considered in accordance with OpenAIRE guidelines and making it available through public repositories (such as Zenodo, GitHub or HuggingFace).
* **Accessibility**: Research data underlying public reports and scientific publications will be deposited and made openly available, if appropriate. Research data will be in secure environments of the project partners Restrictions to access will be applied only on account of privacy, ethical, copyright or confidentiality issues.
* **Interoperability**: The project data and outputs will be described using standard metadata and, whenever possible, terms from controlled vocabularies and ontologies, to enhance semantic interoperability.
* **Reusability**: Potential re-utilisation will be enabled, and the quality of the data ensured by documentation of data collection methods and dataset contents. Synthetic datasets produced will be accompanied with documentation explaining data collection/generation procedures and analysis (e.g., codebooks, methodologies, etc.) and instructions about any tool/software/models that may be necessary for outputs validation, interpretation, and re-use.

Other issues to be considered are: (i) **Curation and storage costs**, all partners generating or reusing research data are responsible for their quality, organization, management, and secure storage and for their deposit for publication and preservation according to the instructions provided in the project Data Management Plan; and (ii) **Code and Model Sharing**, Open-source distribution using established repositories with comprehensive documentation, incl. usage guidelines. Containerization will ensure reproducible computational environments across research sites.

### Integration of Social Sciences and Humanities

Healthcare’s complexities outlined in section 1.1 demand creative, helpful solutions that are acceptable to patients, informal, medical staff and social care personnel. Successful deployment of digital solutions in this cohort must address fundamental issues of digital literacy to promote inclusion and to mitigate inequalities. We will leverage social science and humanities above all in the WP2, since a solid foundation of stakeholder engagement is crucial for the high-risk AI systems we develop. We aim to accomplish this goal by implementing a Co-creation framework, inspired by resources like the DigitalHealthUptake’s material [on digital health stakeholders empowerment,](https://digitalhealthuptake.eu/resource/empowerment-and-capacity-building-of-digital-health-stakeholders/) [Data Saves Lives Ship’s Log](https://static1.squarespace.com/static/6357b43cd13f2053d15e16cf/t/65533945e82faa7101254859/1699952970563/Data_Saves_Lives_Report_ENG_Digital.pdf) and [EUPATI’s patient engagement guidance material](https://toolbox.eupati.eu/guidance/).

# Impact

## Project’s pathways towards impact

**AURORA will drive scientific and technological progress by developing agentic AI systems that help create more efficient human-AI teams.** What drives this impact is AURORA’s novel approach outlined in the Excellence section: pro-active, clinically integrated, compliant, safe, multi-data, human in the loop, patient inclusive. Its pilot deployment provides solid proof of concept, leaving real-world evidence and reusable components for other actors to take developments forward. The project’s pathways towards impact are structured as follows:

### Contribution to the call-specific expected outcomes

#### EO1: Healthcare professionals, have access to user-centric, robust and trustworthy VAs based upon GenAI

AURORA will make GenAI models more functional for healthcare professionals’ workflows. This increases impact of clinical GenAI applications: recent advances demonstrated better decision support for models trained on diverse, high-quality datasets and co-designed with end users. **Scale**: Reach to ≤ 1.83 Mio physicians in the EU [28]. Many already adopting AI tools: 74% of European healthcare organizations increased GenAI investment (2024) [66]. **Significance**: AURORA's AI assistants can reduce healthcare pain points. Workflow efficiency gains: ≤ 20-40% less documentation time; ≤ less 90% in radiotherapy planning time [75]. Healthcare organizations report ≤ 75% enhancement in treatment effectiveness through [92]. Reviews show 77% of AI interventions outperform standard care, 70% demonstrating clinically relevant endpoint improvements [5]. Successful federated learning deployments demonstrate 33% improvement in diagnostic performance while maintaining complete data localization [104].

#### EO2: Healthcare professionals benefit from cross-country applicable methodologies

AURORA will implement a cross-country approach for federated learning, governance models, multi-language, methodology, co-creation with healthcare professionals and patients. This aligns with best practices for cross-border healthcare AI deployment (e.g. in EHDS implementation framework and federated learning protocols [74]). **Scale**: AURORA's cross-country deployment can provide good practices for the 27+ EHDS countries. National online health data access provides the basis for expanding AURORA's federated approach [74, 82]. Federated learning implementations have demonstrated remarkable reach: e.g. 71 institutions, 6 continents (Intel-Penn Medicine); 10 pharma companies (MELLODDY project) [104]. **Significance**: AURORA can contribute improved GenAI cross-border healthcare coordination, towards the €11 bn in savings via the EHDS until 2035 (€5.5 bn from better access/ exchange of health data), (€5.4 bn from optimizing secondary health data use) [63]. 69% of EU citizens trust AI combined with expert judgment; 44% globally are willing to trust AI for diagnosis [17]. Almost half of surveyed healthcare professionals who have used AI report trusting it for decision support and diagnosis [87].

#### EO3: Patients benefit from enhanced outcomes, personalised care, etc.

AURORA will engage patients in the development of its AI agents, to make sure they improve PROMs/PREMs. **Scale**: AURORA addresses substantial patient populations in 3 target diseases, with significant healthcare challenges (see section 1). 9 languages in which we publish the lay summaries cover 290Mio + native speakers.
Potential reach to 449 Mio EU citizens covered by the EHDS framework [6]. **Significance**: Direct and indirect patient benefits from AI virtual assistants. Patients’ satisfaction with virtual assistants for healthcare professionals have not been much assed yet, but reach of 70%+ across multiple patient-facing AI virtual assistants [72]. AI-powered platforms provide enhanced care coordination with 92% accuracy in health assessments [64]. Quality improvements in AI-assisted patient-clinician interactions. reducing communication delays.

#### EO4: Healthcare systems benefit from improved cost-effective patient outcomes….

AURORA’s 3 use cases will demonstrate its added (clinical) value. **Scale**: European AI in healthcare market valued €7.92 bn (2024) (projection: €143.02 bn by 2033 [57]). [57]. Big potential cost savings in AURORA’s target diseases: prostate cancer €8.43 bn; RA €15,637 per patient annually; SLE €14,411 per patient annually [4, 30, 58]. Hospitals could save 15% of their costs through the EHDS shared data systems [88]. **Significance**: Studies demonstrate 450-800% ROI for AI healthcare implementations; virtual assistants generate €63,672 annual benefit per practice [7, 21]. Healthcare systems report 15-25% less operational cost with same care quality [7, 13]. For periodontitis, much bigger indirect (€156,120 Mio) than direct costs (€2,520 Mio) [10], indicate substantial cost-saving potential through early AI-assisted detection and intervention.

### Contribution to Destination Expected Impacts

#### EI1: Health and social care services and systems have improved governance mechanisms…

AURORA embeds technological innovations into clinical workflows, across pilots in healthcare systems spanning Bismarck (BE, DE, RO) and Beveridge (ES, IT, SE). These governance mechanisms can be reused for future federated construction of AI agents. **Scale**: Shortage of ≈1.2 Mio doctors, nurses, midwives (2022; projection 2030: 4 Mio. [62]). AI models can help ease this pain point; AI Healthcare market expected CAGR 47.6% 2023-2028 [45]. Yet, AI needs governance frameworks ease staff shortages. Our governance mechanisms can be reused here. **Significance**: Digital governance frameworks can reduce duplicate testing, fasten diagnoses, improve care coordination [29, 82]. AI-powered supply chain systems prevent shortages of medications and supplies; in pilot studies, these tools optimized resource allocation and cut patient waiting times by over 100 days [75].

#### EI2: Healthcare providers are trained and equipped with the skills…

AURORA provides training for healthcare professionals: comprehensive educational programmes; hands-on AI-tools experience, learning to integrate virtual assistants in workflow, interpret AI outputs, apply recommendations safely. Co-design approach directly involves them in tool development. **Scale**: Substantial need for healthcare professional training, analysis show gaps across EU healthcare education institutions in AI literacy programs [9]. The digital health sector is expected to expand by 20-30% due to EHDS implementation, requiring extensive capacity building [74]. **Significance**: AI training raris healthcare professionals’ diagnostic accuracy (to 95.2%), technology adoption (by 40%), implementation success (by 60%). Competency-based programs reduce training time (by 73%) and medication errors (3.2–5.0% to 1.8%). Organizations adopting AI report 18% less operational costs[1, 9, 70].

#### EI3: Citizens play a key role in managing their own healthcare…

AURORA's AI assistants indirectly support citizens by helping healthcare professionals make better decisions and reduce workload. This helps alleviate patient autonomy pain points e.g. unnecessary hospitalization. **Scale**: Periodontitis and prostate cancer are more elevated in vulnerable groups. Our pilot sites in Northern, Eastern, Southern, and Western Europe offer a diverse population, enabling transferable proof of concept and conclusions. **Significance**: AI-powered platforms provide enhanced care coordination and reduce carer stress with 92% accuracy in health assessments [64]. AI interventions can reduce unnecessary hospitalizations through better diagnostic accuracy and care coordination [75]. Virtual assistants demonstrate 47% more digital appointment bookings and 40% less in routine call volume [72].

#### EI4: Health policy and systems adopt a holistic approach in evaluating health outcomes

AURORA’s holistic approach considers how improvements for healthcare professionals can impact individual and public health outcomes. Individually, it improves clinician's decision making and patient outcomes. Organisationally, it helps lessen the burden of staff and hospital bed shortages. Societally, it reduces costs through unnecessary hospitalization. Our AI agents can easily transfer to other countries, given the cross-country piloting. Reduced hospitalization or repeated exams lessens the health sector's carbon footprint. **Scale**: Pilots span both Bismarck and Beveridge health systems, ensuring solutions work for both. Multiple healthcare organizations report successful AI implementation across different clinical applications, indicating scalable deployment potential [75].
**Significance**: Analysis indicate 8-12% of total healthcare spending value from digital health technologies [42, 68]. Environmental benefits demonstrate 40-70% less emissions from digital health tools compared to traditional methods [55]. AI systems reduce turnaround time (24.68 hrs vs 0.66 hrs) for critical diagnoses [75].

## Measures to maximise impact — Dissemination, exploitation and communication

The **Dissemination, Exploitation** **and Communication** strategy will ensure AURORA’s outcomes are grounded in stakeholder realities, fully exploited and widely shared beyond immediate users. The basis will be a careful stakeholder mapping in T2.1, outlining engagement mechanisms and tools for each group. The communication, dissemination and exploitation goals for each group are outlined below.

| Target group | Goals | D | E | C |
| --- | --- | --- | --- | --- |
| Healthcare professionals | Demonstrate usability, safety, and added value of GenAI assistants in clinical workflows. Promote adoption. | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |
| Patients & carers | Create trust in how AURORA supports personalised care, enhances communication with doctors, and safeguards privacy; Address issues of explainability, inclusion, digital literacy, etc. | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |  | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |
| Hospital & healthcare system leaders | Provide data on operational efficiency, better care pathway, and less staff workload; demonstrate return on investment and value-based healthcare alignment to support future procurement or scale-up. | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |
| Regulators & HTA bodies | Share AURORA’s evidence-generation strategy, regulatory compliance methods (AIA, MDR, EHDSR, GDPR), and clinical utility findings; support early scientific dialogue and prepare for potential HTA processes. | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |  |
| Policy makers | Inform about AURORA’s alignment with EU priorities (EHDS, AIA, Digital Health Strategy); contribute evidence for policy frameworks supporting safe and responsible use of GenAI in healthcare. | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |
| Scientific community | Disseminate methodological advances in agentic systems, multimodal data fusion, fine-tuned LLMs, and federated learning; foster reuse and peer validation of models and datasets; contribute to open science efforts. | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |  | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |
| Industry & developers | Share technical architecture, standards, reference implementations, and open-source outputs; stimulate uptake, reuse, and integration into digital health tools or services by SMEs and startups. | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |
| General public | Raise awareness about the role of trustworthy GenAI in healthcare, highlight benefits and limitations transparently, address concerns about data privacy and safety, and promote citizen engagement in digital health. |  |  | ![Abzeichen Tick1 mit einfarbiger Füllung](data:image/png;base64...) |

Table 1 AURORA target stakeholder groups.

### Communication

The communication strategy will ensure that target groups understand the main messages of the project: the difference GenAI virtual assistants can make for patients and healthcare professionals. Key tools to achieve this goal include: a) sharable media kits: visuals and explainers describing AURORA to healthcare professionals, patients and carers and others; b) one pagers disseminating the project’s work: explaining the concept of AI agents and the difference they can make for patient outcomes in plain language, c) lay summaries on AURORA’s virtual assistants: for patients and carers; d) online communication channels. Online communication uses a project website as primary AURORA knowledge hub, with different sections e.g. for healthcare professionals “How AURORA makes your work easier”, healthcare providers “How AURORA integrates with your workflows”, patients and carers “What AURORA improves for patients”. A tri-annual newsletter will share updates on AURORA’s virtual assistants’ development and piloting. A broad range of social media channels (LinkedIn, Mastodon, YouTube, Instagram) will allow us to reach lay people through specialists. An editorial calendar will combine regular project updates and topical social media campaigns. All partners will contribute their reach on social media channels, to maximize audience. Printed material will be produced especially as hand out to patients in the pilot sites. While most communication material will be in English, we will provide patient-facing pieces additionally in the five pilot sites languages.

| Communication tools | Target audience | KPI |
| --- | --- | --- |
| Project website and social media channels (e.g. LinkedIn, Mastodon, YouTube, Instagram) | Healthcare providers, healthcare professionals, patients and carers, regulators, industry, investors, policymakers, research and innovation networks, journalists, general audience, scientific community. | ≥35.000 unique website views  ≥15 newsletter  ≥ 2,000 combined social media followers  ≥16 comms campaigns |
| Reusable communication packages | Healthcare providers, healthcare professionals, patients and carers, regulators, industry, investors, policymakers, research and innovation networks, journalists, general audience, scientific community. | ≥ 6 media kits with visuals and explainers,≥ 2 factsheets |
| Lay summaries – e.g. “How AURORA helps your doctor” | Patients, informal carers, citizens | ≥ 6 lay summaries in several languages (DA, DE, EN, ES, FR, IT, SV, PO, RO, …) |

### Dissemination

AURORA’s dissemination aims to maximize understanding and uptake of AURORA’s GenAI virtual assistants and the 3 use cases. The strategy focusses on a) sharing a proof of concept of adopt trustworthy, interoperable and multi-country AI solutions; b) creating opportunities for co-design in refining the virtual assistants and clinical use cases, ensuring that the solutions meet real-world and regulatory needs; c) promoting the scientific work (especially from technical WPs) in fairs, academic publications and conferences. The consortium will target international conferences on AI in healthcare, digital health, and clinical applications of GenAI. The table below shows example conferences.

|  |
| --- |
| [Intelligent Health AI](https://intelligenthealth.ai/) l, [AAAI Conference on Artificial Intelligence](https://aaai.org/conference/aaai/) l, [AI for Good Global Summit](https://aiforgood.itu.int/) l, [AI for Health Summit](https://www.aiforhealth.fr/) l, [MEDICA](https://www.medica-tradefair.com/) l, [DMEA](https://www.dmea.de/en) l, [HIMSS European Health Conference & Exhibition](https://www.himss.org/) l, [EHTEL](https://ehtel.eu/) l, [European Federation of Periodontology events](https://www.efp.org/europerio/europerio11/) l, [International Association for Dental Research Annual Meetings](https://www.iadr.org/) l, [European Association of Urology Annual Congress](https://eaucongress.uroweb.org/) l [EAU Section of Urological Research meetings](https://uroweb.org/education-events/events) l, [European Alliance of Associations for Rheumatology Congress](https://congress.eular.org/) l, [BSR Annual Conference](https://www.rheumatology.org.uk/eventslearning/conferences/annualconference#:~:text=Annual%20Conference%20is%20the%20leading,in%20paediatric%20and%20adolescent%20rheumatology) l, etc. |

l = GenAI / digital health / AI in healthcare; l = periodontology related; l = oncology related; l = rheumatology related

AURORA partners will aim to produce scientific articles, linked to technical innovation in AI and architectures, clinical application related to the use cases, regulatory, ethical, and trustworthiness aspects, as well on methodologies, standards, and societal impact of our solutions. Example journals are provided in the table below.

|  |
| --- |
| [Nature Medicine](https://www.nature.com/nm/) lll, [The Lancet Digital Health](https://www.thelancet.com/journals/landig/home) llll, [NPJ Digital Medicine](https://www.nature.com/npjdigitalmed/) llll, [Artificial Intelligence in Medicine](https://www.sciencedirect.com/journal/artificial-intelligence-in-medicine) lll, [IEEE Journal of Biomedical and Health Informatics](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020) ll, [Journal of Medical Internet Research (JMIR)](https://www.jmir.org/) llll, [IEEE Transactions on Medical Imaging](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=42) ll, [BMJ Health & Care Informatics](https://informatics.bmj.com/) llll, [Health Policy and Technology](https://www.sciencedirect.com/journal/health-policy-and-technology) ll, [BMC Medical Ethics](https://bmcmedethics.biomedcentral.com/) ll, [Frontiers in Digital Health](https://www.frontiersin.org/journals/digital-health) llll, [International Journal of Medical Informatics](https://www.sciencedirect.com/journal/international-journal-of-medical-informatics) llll,etc.  Disease specific: [Journal of Periodontology](https://aap.onlinelibrary.wiley.com/journal/19433670), [Prostate Cancer and Prostatic Diseases](https://www.nature.com/pcan/), [European Urology](https://www.europeanurology.com/), [Annals of the Rheumatic Diseases](https://ard.eular.org/), [Arthritis & Rheumatology](https://onlinelibrary.wiley.com/journal/23265205) |

**LEGEND:** l = Technical innovation in AI and architecture; l = Clinical application and evaluation; l = Regulatory, ethical, and trustworthiness frameworks; l = Methodology, standards, and societal/systemic impact

We will also contribute to events targeting specific stakeholder groups, to foster trust, visibility, and uptake of the solutions across Europe: **a) Webinars and tutorials:** learning sessions to train and guide stakeholders on how to use, adapt, and benefit from the developed AI-based virtual assistants. For patients, these sessions will highlight the impact these solutions can have on their care. The tutorials will include step-by-step guides for technical users (e.g., IT teams, developers) on deploying the agentic architecture, hands-on training for healthcare professionals on integrating the assistants into clinical workflows, interpreting outputs, and applying recommendations safely; **b) Demonstration events:** showcasing the developed AI-driven virtual assistants in real clinical environments, combining live demonstrations (e.g. “Meet the AI Assistant”), webinars, and workshops to engage healthcare professionals, patients, policymakers, and industry; highlighting clinical utility, usability and regulatory readiness. All WPs will contribute to deliver dissemination materials, which are built to convey AURORA messages to target actors and encourage them to take up the other outputs. A summary of key dissemination tools is presented below.

|  |  |  |
| --- | --- | --- |
| Dissemination tools | Target audience | KPI |
| Publications in open access journals | Scientific community, health care practitioners, advisors, industry and business partners | ≥ 8 peer reviewed open access publications |
| Nat. & internat. fairs & scientific conferences | Scientific, community, industry, research and innovation networks | ≥ 10 presentations at fairs, conferences or workshops |
| Results portals (OpenAIRE, Zenodo, GitHub, HuggingFace) | Developers, researchers, industry, research and innovation networks | ≥ 8 documents, software interfaces and/or datasets |
| Webinars, tutorials, demos | Healthcare practitioners, health advisors, industry, policymakers | ≥ 3 webinars, tutorials; ≥ 6 demonstration events |
| Hackathons; Standards | Industry, investors, scientific community, innovation networks | 2 hackathons; SDO participation |
| Training sessions | Health care practitioners, health advisors | ≥6 training sessions with ≥100 healthcare professionals trained |
| Clustering meetings with other projects | Scientific community, research and innovation networks, policymakers. | ≥500 unique stakeholders engaged |
| Engagement of EU projects/ initiatives | Synergy projects/initiatives e.g. HORIZON-CL4-INDUSTRY-2025-01-DIGITAL-62; HORIZON-CL4-2025-03-HUMAN-18; EC AI Office; European Digital Innovation Hubs, SHAIPED, etc. | ≥ 4 webinar/ event sessions with synergy projects |
| Final (online) conference | Health care practitioners, developers, health advisors, policymakers, investors, research innovation networks, journalists | > 60 registrations |

AURORA will host a high-profile final conference to present its key results and impact. The event will gather healthcare professionals, patients, policymakers, patient representatives, industry, and researchers to showcase the validated virtual assistants and lessons learned from the clinical pilots. It will feature live demonstrations (using materials from the demonstration event), panel discussions, and dedicated sessions on clinical, regulatory, and societal aspects of trustworthy AI in healthcare. The conference will be a platform for knowledge exchange, exploitation opportunities, and fostering sustainability of the project outcomes beyond its lifetime.

### Exploitation

Exploitation activities will ensure the project’s results are positioned for sustainable uptake and long-term impact in healthcare and suitable to advance research. The consortium will identify and prioritize the project’s Key Exploitable Results using a co-design approach with the project pilots and stakeholders, establishing clear ownership and access rights. The table below gives an initial selection.

| Key Exploitable Result | Exploitation Goals | Potential End Users |
| --- | --- | --- |
| Trustworthy & validated training datasets | Ensure high-quality data for model training & reduce biases | AI developers, Healthcare professionals |
| GenAI models for virtual assistants | Provide personalized support to healthcare professionals | Healthcare professionals, Patients |
| Agentic reference architecture implementation for GenAI solutions compliant with interoperability & regulatory requirements | Provide an extensible and interoperable deployment environment for innovative AI solutions in healthcare | Industry and SMEs, IT departments from clinical institutions, researchers in the health sector |
| Methodologies for cross-country AI tool acceptance | Facilitate the integration of AI tools across different healthcare systems | Healthcare systems, Policymakers |
| Clinical utility assessments of AI solutions | Demonstrate effectiveness in real-world healthcare scenarios | Healthcare professionals, Patients |
| Regulatory strategy for AI tools | Ensure compliance with EU regulations and standards | Regulatory bodies, Healthcare providers |
| Continuous assessment methodologies for AI solutions | Maintain trustworthiness and ethical use of AI in healthcare | Researchers in the healthcare sector, Ethics committees |
| Open-source frameworks for AI model sharing | Promote collaboration and innovation in AI development | Developers and Researchers in the healthcare sector |
| Training programs for healthcare professionals | Enhance skills and knowledge in using AI tools | Healthcare professionals, Institutions |

Table 2 List of exploitable results.

The analysis of the KERs will be complemented bv a thorough market and competitor analyses to benchmark the results, highlight their unique value, and define effective positioning strategies.

#### Regulatory Pathway and Exploitation analysis

AURORA will examine the economic and health system impact of its AI solutions. This includes assessing potential cost savings and efficiency gains in its two development stages: a) foundational model stage: earlier detection of disease and better identification of comorbidities can reduce unnecessary procedures, accelerate appropriate interventions, and improve patient outcomes—leading to long-term savings for health systems. b) agentic system stage: assistants can reduce clinician workload by automating routine tasks, streamlining documentation, and enhancing care coordination, contributing to operational efficiency and resource optimization.

To ensure long-term impact and adoption, an exploitation pathway analysis will evaluate the sustainability, scalability, and economic value of our approach. We will identify potential routes to integration in clinical practice, business models for maintenance, and alignment with policy and reimbursement frameworks. These efforts will demonstrate how agentic AI can deliver not only clinical benefit but also tangible economic value for hospitals and healthcare systems. AURORA will follow a clear regulatory pathway in accordance with the AIA and relevant medical device regulations, advancing certification and safe deployment of agentic assistants in healthcare.

#### Management of intellectual property

We will clearly define the rules for the management of project created knowledge and IPRs, manage them in the Consortium Agreement and monitor them in WP3. Initial principles include: Ownership of Background Knowledge: (i) Access rights to pre-existing know-how necessary for the implementation of the project will be made available to the Consortium members royalty-free; (ii) Access rights to the background knowledge for dissemination, and academic purposes shall be granted to the Consortium members royalty-free; (iii) All background knowledge IPRs will be retained by the corresponding consortium partners after the completion of the project. Ownership of Foreground Knowledge: (i) IPR of the foreground knowledge produced by the consortium partners during the implementation of the project will be retained by the corresponding partners and divided proportionally, according to the effort invested in its production (project results), (ii) Foreground knowledge will be made available on a royalty-free basis to all project partners for dissemination and academic purposes only, after the project conclusion. Also, consortium partners agree on an open-source approach to the exploitation of the results, whenever feasible. To guarantee sustainability of the results and future applicability within daily clinical practice, a dual licensing mode is likely to be implemented by some of the project results.

## Summary

|  |  |  |
| --- | --- | --- |
| SPECIFIC NEEDS | EXPECTED RESULTS | D & E & C MEASURES |
| **System-level needs**: Healthcare systems across Europe face rising costs, an aging population, chronic disease prevalence, workforce shortages, and increasing demands for data-driven efficiency. Current AI solutions remain fragmented, reactive, opaque, and often non-compliant with regulations, limiting trust and uptake.  **Rheumatology**: Chronic conditions characterized by high disease heterogeneity, complex multi-organ involvement, and fluctuating trajectories. HCPs struggle to balance risks of over-therapy associated side effects (e.g., infections, comorbidities) & undertreatment (joint destruction, organ failure, disability). Flare prediction still an unmet clinical need. Discontinuity of care across providers leads to therapeutic inertia.  **Oncology**: In metastatic prostate cancer, there is huge variability in outcome and life expectancy between patients; validated tools to guide individualized choice between the multiple treatment options (AR and PARP inhibitors, chemotherapy, radiotherapy) are lacking. AI support can support personalized medicine.  **Periodontology**: Chronic, highly prevalent conditions (periodontitis, peri-implantitis) leading to teeth loss, impaired function and systemic comorbidities. Labour-intensive diagnosis, subjective & often delayed until irreversible damage. HCPs face uncertainty in predicting treatment outcomes and tailoring supportive therapy intervals, leading to over- and undertreatment. Flare prediction and personalized maintenance remain major unmet needs.  **General unmet need**: HCPs and patients require effective, explainable, agentic GenAI assistants that integrate multimodal data, tie into clinical workflows, are interoperable and multilingual, and align with GDPR, MDR, AIA & EHDS to ensure trustworthy uptake. | **General result**: Federated, EHDS-ready GenAI architecture enabling secure, cross-border integration of multimodal health data; open-source, multilingual foundation models with built-in fairness, transparency, and bias monitoring; and a regulatory and HTA-aligned evidence generation framework that supports clinical validation and facilitates adoption.  **Rheumatology**: Validated VAs integrated into routine rheumatology care for 100 patients across DE, IT and RO. Outputs include risk stratification for flare prediction, guideline-conform therapy continuation or de-escalation recommendations, and iterative assistant prototypes refined through stakeholder feedback.  **Oncology**: Validated VAs combining clinical data, imaging, digital pathology and genomics to refine prognostic groups and accurately predict therapy response. The model will be trained on 850 retrospective patients, externally validated on 150 patients, embedded into federated infrastructures.  **Periodontology**: Validated VAs for screening, diagnostic, treatment response prediction, and personalized supportive therapy, integrated into clinical workflows. Outputs include validated accuracy against gold-standard periodontal assessments, prospective testing in 400–500 patients, and user feedback from both clinicians and patients ensuring acceptability and usability.  **Cross-project results**: Clinical-grade datasets, open-source models, detailed clinical protocols, and key deliverables (e.g., WP5 models, WP8 clinical evaluations, WP3 regulatory roadmap) ensuring scientific and societal impact. | **Dissemination**: ≥8 open-access publications in oncology, rheumatology and periodontology journals; ≥10 presentations at major conferences. ≥3 tutorials, ≥6 demonstration events, ≥2 hackathons, ≥ 6 training sessions, ≥ 4 meetings with synergy projects. 8 OS releases on GitHub, HuggingFace, Zenodo. Study protocols officially registered.  **Communication**: Dedicated AURORA website and tools for multi-lingual outreach – e.g. 6 media kits, 2 factsheets, 6 lay summaries for patients, infographics, explainers on periodontic disease prevention, RA flare management, and prostate cancer therapy decisions. Expected impact: ≥35,000 web views, ≥2,000 followers across platforms, 16 communication campaigns; media outreach to patient associations, clinical societies.  **Exploitation**: Identification of KERs: validated VA, reference architecture, training datasets, regulatory strategy, HTA evidence packages, lay summaries, stakeholder engagement model. Each use case offers adoption pathways: AI-based prognostic tools in oncology, AI flare prediction in rheumatology, and AI-driven diagnostics in periodontology. Industry partners and SMEs will be engaged for commercial exploitation and technology transfer.  **Engagement**: Structured webinars and workshops for target groups - e.g. to discuss pain points, review protocols, test usability, provide feedback on AI explainability. (e.g. “Meet the AI Assistant”). Demonstration events and a final conference will amplify results and foster adoption. |

| TARGET GROUPS | OUTCOMES | IMPACTS |
| --- | --- | --- |
| **HCPs**: oncologists, rheumatologists, periodontologists, nurses, and IT/clinical support staff integrating assistants into workflows.  **Patients and caregivers**: individuals with prostate cancer, RA/SLE, or periodontic diseases, benefiting from better healthcare outcomes.  **Hospital and healthcare system decision makers**: managers, administrators, and payers seeking efficiency, improved outcomes, and value-based care.  **Regulators and HTA bodies**: national authorities and EU-level networks engaged through scientific advice, regulatory roadmaps, and HTA evidence packages.  **Policy makers**: ministries, DG SANTE, EMA, aligning with the EHDS, AIA, and Europe’s Beating Cancer Plan.  **Scientific community**: AI researchers, clinicians, ethicists, and SSH experts advancing multidisciplinary innovation and evaluation.  **Industry, tech developers**: SMEs, MedTech, digital health startups, and HIS vendors adopting AURORA’s OS outputs.  **General public**: citizens, patient associations, employers and professional societies engaged through transparent communication to build trust in GenAI. | **Rheumatology**: Proof-of-concept validation of flare prediction Vas in 3 EU ERN centerers including a LMIC center; reduced unnecessary long-term immunomodulatory & suppressive exposure and/or early escalation of immunomodulatory/-suppressive medication; prevention of irreversible joint/organ damage. Patients, clinicians and other stakeholders from the healthcare system benefit from improved decision confidence, personalised care, and better clinical outcomes. Better adherence.  **Oncology**: AI-enhanced stratification reducing overtreatment in low-risk groups and ensuring timely escalation in high-risk patients. Improved survival outcomes, better quality of life, and optimized use of costly therapies. External validation across two European cohorts demonstrates robustness.  **Periodontology**: AI-assisted screening, risk assessment, and predictive management enable earlier detection of periodontitis and peri-implantitis, personalized treatment planning, and optimized supportive therapy intervals. Clinicians benefit from improved decision-making, reduced disease progression, and better allocation of interventions, while patients experience enhanced monitoring, tailored care, and higher engagement in treatment.  **Cross-case outcomes**: EHDS-compliant components demonstrated in clinical sites in 6 European countries. Training in GenAI application provided to ≥200 HCPs. Higher levels of HCP satisfaction and workflow efficiency reported through the availability of explainable, transparent, bias-monitored AI outputs. Validated HTA evidence packages prepared for adoption, enabling alignment with national regulatory and reimbursement frameworks. Methodological foundation for GenAI validation and adoption established, with relevance beyond 3 medical fields.  **Stakeholder benefits**: Regulators gain robust safety/efficacy data; SMEs gain reusable AI building blocks; patients gain trust, better outcomes and transparent information | **Scientific**: Breakthroughs in federated architectures, explainable, agentic multimodal GenAI validated in 3 medical fields, with clinical evidence from pilot sites. Integration of multiple data sources enhancing robustness and ensuring broad applicability. Publication in high-impact journals; contributions to conferences; open access to selected datasets, models ensure uptake and reusability by scientific community.  **Healthcare**: Improved patient management in 3 domains. More precise and individualized therapies. HCPs benefit from reduced workload, time savings, and reliable decision-support in complex care, while patients gain confidence in treatment pathways. Validation across several European healthcare systems ensures results transferable beyond our pilot sites.  **Economic**: Reduced costs through reduced administrative burden, precision allocation of expensive drugs in oncology, decreased adverse events and hospitalizations in RA/SLE, and prevention and improved treatment in periodontology. Healthcare system savings and improved productivity for patients. Cross-country models increase economies of scale.  **Policy/regulatory**: Evidence supporting EHDS secondary use of health data, AIA adaptations for clinical GenAI, new HTA pathways for AI-based decision support. AURORA positions Europe as a leader in safe GenAI adoption in medicine.  **Societal**: Empowered patients with transparent, interpretable AI outputs. Increased equity supporting multiple languages and addressing gender and socio-demographic differences. Enhanced trust in digital health and AI.  **Sustainability**: AI assistants reduce waste of resources by avoiding unnecessary treatments and interventions, indirectly lowering environmental burden. Agentic architecture ensures reusability and sustainability across diseases and countries. |

# Quality and efficiency of the implementation

## Work plan and resources

AURORA is a 54 months project structured into 9 work packages (WPs), designed to combine technical competence, clinical expertise, innovation, and regulatory capabilities. Figure 2 presents a simplified PERT chart showing the work package interrelations.

| WP # | Work Package Title | Lead Part. No | Lead Part. Short Name | PMs | Start Month | End month |
| --- | --- | --- | --- | --- | --- | --- |
| WP1 | Project Management and Coordination | 1 | Fraunhofer | 60 | 1 | 54 |
| WP2 | Dissemination, Exploitation, Communication & Stakeholder Engagement | 12 | empirica | 96 | 1 | 54 |
| WP3 | Regulatory, Ethical and Trustworthiness Framework | 10 | TRI | 194 | 1 | 54 |
| WP4 | User Requirements. Clinical Use Cases monitoring | 3, 5, 6 | CHUL, UDUS, VHIO | 420 | 1 | 54 |
| WP5 | AI Model Evaluation, Training and Deployment | 2 | BSC | 181 | 1 | 39 |
| WP6 | Reference Architecture and Interoperability | 1 | Fraunhofer | 79 | 1 | 42 |
| WP7 | Cloud infrastructure and Continuous Integration | 1 | Fraunhofer | 78 | 7 | 54 |
| WP8 | Development and evaluation of VAs | 4 | NTT Data | 130 | 10 | 54 |
| WP9 | Data Management and Integration | 15 | FPS | 125 | 1 | 54 |

Table 3. List of work packages.

![](data:image/png;base64...)

Figure 2 Simplified PERT overview of the project.

### Work package descriptions

|  |  |
| --- | --- |
| **Work package number** | 1 |
| **Work package title** | Project Management and Coordination |
| **Objectives**   * Ensure effective management of the project including communication between the Consortium and the EC, so that all knowledge is created, managed, disseminated and exploited in a coordinated and coherent manner and that all activities are managed to a high standard. * Monitor progress and ensure quality and timely delivery of results. * Assess and mitigate any potential or identified risks to the project. * Ensure compliance with EC rules, ethics, and reporting requirements. | |
| **Description of work**  **Task 1.1: Project Coordination and Governance (M1-M54).** Leader: Fraunhofer, Contributors: All  The coordinator will establish the project governance structure (e.g., General Assembly, Steering Committee) and the corresponding infrastructure e.g., workspace, document repository, mailing lists, issue tracker. The coordinator oversees all administrative tasks, incl. a) communication with the EC; b) organisation of regular meetings and minutes; c) compilation and submission of cost statements and of all the contractual periodic and final reports; d) resolution of administrative or contractual issues: e) preparation of the **Consortium and** **Data Protection/Joint Controller Agreements**; c) coordination with the Advisory Board, together with WP2.  **Task 1.2: Progress monitoring and risk management (M1-M54).** Leader: Fraunhofer, Contributors: All  Control of progress during the project, ensuring that the project schedule is met. The coordinator will organise peer reviews of deliverables to ensure quality and relevance. Any minor deviations from the project plan will be reported to the General Assembly/Steering Committee. Progress monitoring involves: a) monitoring of deliverables, milestones, progress and final reports; b) review of project progress against the objectives and KPIs; c) monitoring of compliance by the partners with their obligations; d) development of the contingency plans in case difficulties and risks arise. | |

|  |  |
| --- | --- |
| **Work package number** | 2 |
| **Work package title** | Dissemination, Exploitation, Communication, and Outreach |
| **Objectives**   * Promote AURORA, maximise its visibility, inform about its results to a broad audience on various channels. * Engage stakeholders, facilitate knowledge exchange, support them to further build on AURORA’s results. * Coordinate exploitation activities aimed to ensure the uptake, sustainability and impact of the project’s Key Exploitable Results. Define strategies for market positioning, intellectual property management, alignment with regulatory requirements, and integration into relevant policy and standardisation frameworks. | |
| **Description of work**  **Task 2.1: Dissemination, Communication & Outreach Strategy (M1-M6).** Leader: empirica, Contributors: All  T2.1 will develop the dissemination, communication and outreach strategy. It will identify the main target groups, differentiating between end users and affected stakeholders and outlining the group’s interest and influence, considering EC guidance in the [*Better Regulation Toolbox*](https://commission.europa.eu/law/law-making-process/better-regulation/better-regulation-guidelines-and-toolbox/better-regulation-toolbox_en). For each stakeholder group, it will craft compelling key messages and determine appropriate outreach channels and promotional material. We will outline the desired communication and dissemination KPIs and assign responsibilities among partners. An event calendar will track events and other engagement opportunities. Task lead empirica will monitor the strategy’s execution to ensure it supports all elements of the project and appropriately informs and engages stakeholders.  **Task 2.2: External communication, Content Production, Events and Media Campaigns** **(M1-M54)**. Leader: empirica, Contributors:  CHUL, AU, UGOT, UNIPI, UDUS, KEM, VHIO, AOUI VR, SOLTI  T2.2 will execute the communications, dissemination and outreach strategy (T2.1) through various channels and events. empirica will set up project website as central information channel, with at least WCAG standards level 2. Social Media channels (e.g. LinkedIn, mastodon, YouTube) will give regular project updates, hold campaigns on project milestones and interact with the stakeholder community. One patient engagement tool will be lay summaries in at least all pilot languages (CA, DA, DE, EN, ES, FR, IT, RO SV). empirica coordinates content production, receiving content input from the relevant WPs, to produce reusable content in various forms: press releases, articles, visuals, possibly also podcasts.  **Task 2.3: Stakeholder Engagement** **(M4-M54).** Leader: empirica, Contributors: All  T2.3 will establish an inclusive stakeholder engagement process to help the co-design, validation, and uptake of the AURORA virtual assistants. It will build on the stakeholder analysis performed in Task 2.1 and the user mapping conducted in WP4 target key groups outlined in section 2.2. It will also help T3.6 understand stakeholder perceptions on trust. We will create a stakeholder engagement group with representatives from all target groups. Patient representatives will also integrate the Advisory Board. This will be formalised in a published engagement protocol in D2.2. Stakeholder engagement formats will include consultation and co-creation workshops, “Meet the AI agents” webinars, structured interviews, and user validation sessions, tailored to different project phases: Early engagement will focus on collecting needs and expectations, while mid- and late-stage engagement will concentrate on validating system design choices, user experience , ethical and trust-related dimensions, and adoption strategies. Three iterations of D2.5 will report on the stakeholder engagement throughout the project.  **Task 2.4: Exploitation Planning** **(M12-M54)**. Leader: empirica, Contributors: All  T2.4 will develop exploitation roadmap to maximise the uptake and sustainability of AURORA’s results. We will identify Key Exploitable Results, with their technical maturity, relevance, and value for different stakeholder groups. We will define exploitation readiness indicators covering e.g. technical maturity, regulatory compliance, and market positioning.  A market analysis will study needs, competing solutions and positioning strategies. IP management. will include provisions for patenting, licensing, and open-source strategies, as well as alignment with regulatory and ethical requirements.  AURORA will explore business and sustainability models to ensure long-term impact , like integration into healthcare provider workflows. T2.4 will also identify how the project results can contribute to relevant EU and national policies, standardisation efforts, and public procurement. In collaboration with WP3, T2.4 will ensure that all results align with EU regulations and HTA requirements. Collaboration with T6.4 on EHDS compliance will further facilitate certification, reimbursement, and adoption. | |

|  |  |
| --- | --- |
| **Work package number** | 3 |
| **Work package title** | Regulatory, Ethical and Trustworthiness Readiness |
| **Objectives**   * Identify ethical and legal issues from using GenAI solutions concerning AURORA use cases and beyond * Review existing EU and national legislation from project jurisdictions and health data use or re-use standards. Provide guidelines for data collection, sharing and processing. Comply with data protection and security rules, * Adopt GenAI development practices based on existing regulatory, ethical, and trustworthiness requirements. * Understand trust-building in diagnosis with AURORA case studies. * Explore regulatory testing and validation of project tools. * Continually assess compliance with regulatory, ethical, and trustworthiness requirements. * Deliver HTA preparedness per use case. | |
| **Description of work**  **Task 3.1: Mapping Current AI Adoption Practices (M1-M6)**. Leader: TRI/ Participants: LIBRe, FPS, JU, empirica  Produce a concise regulatory gap analysis translating GDPR, AIA, MDR, EHDS and related initiatives into actionable ethical/legal requirements for AURORA. Synthesize academic evidence and stakeholder input (incl. from HTAs and payers) on GenAI for prediction/diagnosis and the applicability of privacy-by-design, data-protection-by-design (and by default), and security-by-design. Map EU and participating national laws and relevant standards on health-data collection, processing and sharing (emphasis on EHRs and medical devices) via desk research and a legal questionnaire capturing translated provisions, practice and case law. Document how target stakeholders use GenAI: through observations, interviews, surveys, desk research, analysing adoption patterns, drivers, barriers and governance. Deliver AI-literacy workshops on different biases and compile best-practice, ethical, scalable implementations—identifying “what good looks like” to inform T3.2/T3.3/T3.4.  **Task 3.2: Ethical and Legal AI Framework (M1-M54).** Leader: TRI/Participants: All  Create and continuously update an Ethical and Legal AI framework to ensure (i) that the project partners and the AURORA technologies adhere to the highest ethical and legal standards, rights and principles, and (ii) to identify, analyse, and mitigate potential privacy, ethical, legal and social issues from using the GenAI solutions. An integrated privacy, ethical, legal and social impact assessment will be conducted, to identify emerging issues, implement mitigation strategies, and update the Ethical and Legal AI Framework. Compliance will be monitored and managed with a risk management and AI governance platform (STRIAD-AI Assurance). The Ethical & Legal AI Framework will be aligned with real-world evaluation pathways; define minimal quantitative trust metrics linking with T5.4 and human-factors checks for pilots WP8.  **Task 3.3: Legal and Regulatory Conformity (M1-M54)**. Leader: LIBRe/Participants: All  We will perform a legal conformity assessment of project tools and services with the requirements mapped and related healthcare, privacy and security standards. This includes e.g. a) EHDS regulation compliance regarding the use of electronic health data and related interoperability issues; b) GDPR on personal data protection; c) MDR regarding quality and risk management requirements; d) AIA on AI research, development, and deployment; e) Product Liability Directive on product’s safety; f) related topics in Data Governance Act, Data Act, Network and Information Systems Directive, etc. T3.3 will feed the software development lifecycle under WP5-WP8 and deliver specific considerations for the Ethical and Legal AI Framework under T3.2. This task will provide legal and licensing input to T5.2 on LLM architecture selection and adaptation of the foundation models. The technical documentation (e.g., model cards, data set disclosures etc.) will be studied and the benchmarking results from T5.5 will be considered, to help select models that conform to the requirements for designing high-risk AI systems under Chapter III of the AIA.  **Task 3.4: Reflexivity Framework for Trust in AI Diagnosis (M1–M52)**. Leader: JU/Participants: TRI, UDUS, VHIO, CHUL, KEM, UNIPI, UMF, AU, UGOT, SOLTI  T3.4 will foster reflexivity across the consortium to ensure dataset and model design choices are transparent and socially robust. All members will keep bi-annual reflexive diaries, complemented by milestone-based workshops with the Consortium and Advisory Board. Reflexivity will cover multiple dimensions: personal (values, positionality, life experiences), field related (shaping of assumptions within one’s academic fields), professional (organizational norms), and institutional (structures, interests, power relations). It also includes attention to modality, i.e., how past, present, and possible futures shape decision-making during project development. The process will document inclusion and exclusion choices on decisions and project implementation, datasets, guidelines, and external knowledge, while observing collaboration, power dynamics, and the social. Potential biases, limitations, and representational gaps will be analysed. Findings will feed into technical WPs and T3.2.  **Task 3.5: Media and Public Discourses on Trust in Medicine and AI (M1–M24).** Leader: JU/Participants: TRI, UDUS, VHIO, CHUL, KEM, UNIPI, UMF, AU, UGOT, SOLTI  The aim of this task is to identify public perceptions of AI in healthcare by analysing European discourses. First, A large-scale corpus of EU press articles will be compiled and expanded using datasets from major social media platforms, such as X TikTok and Instagram. A computational discourse analysis will be conducted using keywords such as 'trust', 'distrust', 'health', 'healthcare', 'medicine', 'doctors' and 'AI'. The outcome will be a comparative analysis of discourses of trust and distrust in healthcare and AI across 10 European countries.  **Task 3.6: Understanding Trust in Diagnosis (M12–M48).** Leader: JU/Participants: TRI, UDUS, VHIO, CHUL, KEM, UNIPI, UMF, AU, UGOT, SOLTI, empirica  T3.6 will engage healthcare professionals and patients in co-design processes across rheumatology, oncology and periodontology. To understand the factors contributing to trust/distrust in diagnosis, focus group interviews (FGIs) and workshops will be conducted with clinicians, patients, and patient organisations in consortium partner countries, in conjunction with Task 2.3. This aims to explore what fosters or undermines trust in AI-assisted diagnosis, and to identify user requirements for the further development of the product. The results will feed into recommendations for design principles and trust-enhancing mechanisms for the AURORA platform.  **Task 3.7: HTA Preparedness (M6–M54).** Lead: FPS/Participants: TRI, LIBRe  Operationalise HTA preparedness per use case, bridging regulatory/ethical requirements with value for patients, professionals and healthcare systems. Define value propositions & comparators; specify outcomes and minimal datasets (clinical endpoints, safety signals, usability/human-factors, PROMs/PREMs, resource use); create an evidence-to-requirement traceability matrix; assemble HTA readiness packages (evidence matrices, concise summaries of effectiveness/safety, scoping economic/budget-impact notes).  **T3.8: Regulatory Testing and Experimentation in Healthcare (M13-M48).** Leader LIBRe/Participants: All  Building on the framework for regulatory sandboxes in the AIA, T3.8 will liaise with the national competent authority in Bulgaria to establish AI regulatory sandboxes (under AIA) to test and validate the project tools. Where feasible, T3.8, through partner organisations, will also liaise with respective competent authorities responsible for AI regulatory sandboxes in other Member States, as well as the single information platform developed under Article 57(8) and 62(3)(b) of the AI Act. We will explore opportunities for bridging regulatory sandbox testing with access to the testing and experimentation facilities in the various TEF-Health. T3.8 will also explore quantitative benchmarks used to test and evaluate AI models in healthcare and will assess their trustworthiness from the perspective of the Anglo-centricity of benchmarking datasets, their construct and benchmark's narrow diversity and scope. T3.8 will work towards standardised methods for assessing the trustworthiness of benchmarks from an applied and regulatory perspective. Policy prototyping workshops with stakeholders identified in T3.6 will be conducted, with the feedback received to be communicated to competent authorities and the consortium. | |

|  |  |
| --- | --- |
| **Work package number** | 4 |
| **Work package title** | User Requirements. Clinical Use Cases Monitoring |
| **Objectives**  WP4 coordinates the clinical studies and continuous user-driven validation of AURORA in three medical fields: Rheumatology, Oncology, and Periodontology. It also captures user and stakeholder requirements to guide the development of trustworthy GenAI models (WP5) and VAs (WP8). The core tasks are:   * Capture and consolidate user (HCPs and patients) and other stakeholder requirements for AURORA’s VAs and GenAI models and formally hand them over to WP5 and WP8. * Plan, initiate and monitor the clinical studies of the 3 medical fields, ensuring harmonised procedures across sites. * Ensure compliance with EC clinical study obligations: registration in a WHO‑compliant registry, final regulator/ethics‑approved protocol before first enrolment, midterm recruitment reporting at 50% inclusion, and results‑posting status reporting. * Provide continuous feedback loops and curated clinical evidence to improve models and VA designs, while safeguarding participants’ rights and data. | |
| **Description of work**  **Task 4.1: Co-creation & User/Stakeholder Requirements (M1–M6).** Lead: Fraunhofer; Contributors: All  Elicit requirements via co-design workshops, interviews, and UX studies with HCPs, patients (where appropriate), and other stakeholders. Produce user journeys and success criteria; derive measurable model requirements (data, outputs, safety, explainability, uncertainty) and VA requirements (tasks, guardrails, integration points). Establish traceability criteria.  **Rheumatology Use Case. Lead: UDUS/Participants: UNIPI, UMF, KEM**  **Task 4-RHE.1: Study setup and initiation (per study)**  Finalize study protocol; obtain ethical approvals; register the study in a WHO-compliant registry; set up sites, train staff, and configure data capture and safety monitoring aligned with WP3 and WP9. Where applicable, prepare non-VA baseline workflows to enable pre-VA phases before M18.  *Mandatory EC deliverable per study — Study initiation package (due before first enrolment)*  Indicative subtasks & durations (per study):   * ST1 Protocol finalisation & ethics/regulatory approvals — M6–M18. * ST2 Study registration, contracts, and site initiation — M10–M16. * ST3 Baseline (pre-VA) workflow configuration & dry-run — M14–M18 (no VA usage before M18).   **Task 4-RHE.2 Recruitment, monitoring and midterm report (per study)**  Conduct recruitment; monitor enrolment across sites; manage deviations and corrective actions. Provide interim data quality checks and feedback to WP5/WP8 to refine models and VAs. VA-dependent activities start at M18.  *Mandatory EC deliverable per study — Midterm recruitment report (due at 50% recruitment)*:  Indicative subtasks & durations (per study):   * ST4 VA integration & clinician training — M18–M22. * ST5 Active recruitment & follow-up — M18–M36 (target 50% recruitment around M27–M30, site-dependent). * ST6 Continuous monitoring, data quality & safety surveillance — M18–M48.   **Task 4-RHE.3 Study close-out and results-posting status (per study)**  Prepare results-posting plan and ensure summary results are posted in the applicable registry, even if posting occurs after project end. Coordinate with WP2 for dissemination (where appropriate) and with WP3 for compliance.  *Mandatory EC deliverable per study — Report on the status of posting results (scheduled when results posting is expected or by the last months of the project)*  Indicative subtasks & durations (per study):   * ST7 Database lock, analysis & study close-out — M40–M48. * ST8 Results posting preparation & status reporting — M48–M54.   **Oncology Use Case. Lead: VHIO/Participants: AOUI VR, SOLTI**  **Task 4-ONC.1: Study setup and initiation (per study)**  Finalize study protocol; obtain ethical approvals; register the study in a WHO-compliant registry; set up sites, train staff, and configure data capture and safety monitoring aligned with WP3 and WP9. Where applicable, prepare non-VA baseline workflows to enable pre-VA phases before M18.  *Mandatory EC deliverable per study — Study initiation package (due before first enrolment)*  Indicative subtasks & durations (per study):   * ST1 Protocol finalisation & ethics/regulatory approvals — M6–M18. * ST2 Study registration, contracts, and site initiation — M10–M16. * ST3 Baseline (pre-VA) workflow configuration & dry-run — M14–M18 (no VA usage before M18).   **Task 4-ONC.2 Recruitment, monitoring and midterm report (per study)**  Conduct recruitment; monitor enrolment across sites; manage deviations and corrective actions. Provide interim data quality checks and feedback to WP5/WP8 to refine models and VAs. VA-dependent activities start at M18.  *Mandatory EC deliverable per study — Midterm recruitment report (due at 50% recruitment)*:  Indicative subtasks & durations (per study):   * ST4 VA integration & clinician training — M18–M22. * ST5 Active recruitment & follow-up — M18–M36 (target 50% recruitment around M27–M30, site-dependent). * ST6 Continuous monitoring, data quality & safety surveillance — M18–M48.   **Task 4-ONC.3 Study close-out and results-posting status (per study)**  Prepare results-posting plan and ensure summary results are posted in the applicable registry, even if posting occurs after project end. Coordinate with WP2 for dissemination (where appropriate) and with WP3 for compliance.  *Mandatory EC deliverable per study — Report on the status of posting results (scheduled when results posting is expected or by the last months of the project)*  Indicative subtasks & durations (per study):   * ST7 Database lock, analysis & study close-out — M40–M48. * ST8 Results posting preparation & status reporting — M48–M54.   **Periodontology Use Case. Lead: CHUL/Participants: AU, UGOT, UNIPI**  **Task 4-PER.1: Study setup and initiation (per study)**  Finalize study protocol; obtain ethical approvals; register the study in a WHO-compliant registry; set up sites, train staff, and configure data capture and safety monitoring aligned with WP3 and WP9. Where applicable, prepare non-VA baseline workflows to enable pre-VA phases before M18.  *Mandatory EC deliverable per study — Study initiation package (due before first enrolment)*  Indicative subtasks & durations (per study):   * ST1 Protocol finalisation & ethics/regulatory approvals — M6–M18. * ST2 Study registration, contracts, and site initiation — M10–M16. * ST3 Baseline (pre-VA) workflow configuration & dry-run — M14–M18 (no VA usage before M18).   **Task 4-PER.2 Recruitment, monitoring and midterm report (per study)**  Conduct recruitment; monitor enrolment across sites; manage deviations and corrective actions. Provide interim data quality checks and feedback to WP5/WP8 to refine models and VAs. VA-dependent activities start at M18.  *Mandatory EC deliverable per study — Midterm recruitment report (due at 50% recruitment)*:  Indicative subtasks & durations (per study):   * ST4 VA integration & clinician training — M18–M22. * ST5 Active recruitment & follow-up — M18–M36 (target 50% recruitment around M27–M30, site-dependent). * ST6 Continuous monitoring, data quality & safety surveillance — M18–M48.   **Task 4-PER.3 Study close-out and results-posting status (per study)**  Prepare results-posting plan and ensure summary results are posted in the applicable registry, even if posting occurs after project end. Coordinate with WP2 for dissemination (where appropriate) and with WP3 for compliance.  *Mandatory EC deliverable per study — Report on the status of posting results (scheduled when results posting is expected or by the last months of the project)*  Indicative subtasks & durations (per study):   * ST7 Database lock, analysis & study close-out — M40–M48. * ST8 Results posting preparation & status reporting — M48–M54. | |

|  |  |
| --- | --- |
| **Work package number** | 5 |
| **Work package title** | AI Model Evaluation, Training and Deployment |
| **Objectives**   * Fine-tune both LLMs and VLMs for multimodal healthcare data, adapted to address our clinical use cases in rheumatology, oncology, and periodontology * Implement a Compliance-by-Design framework ensuring AIA compliance, GDPR-by-design data processing, and MDR alignment integrated into the training pipeline * Establish comprehensive bias detection and fairness evaluation frameworks, including automated methods for continuous monitoring across demographic groups * Create a multi-scale foundation model ecosystem with varying computational requirements, enabling deployment from edge computing to high-performance environments * Integrate uncertainty quantification and confidence calibration mechanisms for clinical decision support * Ensure models are validated by humans, compliant with explainability, safety, and regulatory requirements according to EU Trustworthy AI guidelines | |
| **Description of work**  This WP is integrated with the **pre-processed datasets received from WP9 (D9.1—3)**, together with the requirements from WP3 and WP4. The core technical work is carried out by BSC, Fraunhofer, NTT Data, RWTH and FPS. The other partners contribute with clinical evaluation input and regulatory requirements. Each of the tasks will develop models tailored to the 3 medical fields of the project.  **Task 5.1: LLM selection and adaptation (M1-M36)** – Lead: Fraunhofer/Participants: All  Evaluate and benchmark existing open-source foundation models (section 1.2.2). Implement systematic comparison methodology using curated clinical datasets. Execute architecture adaptation for healthcare contexts, incorporating medical terminology preservation and multilingual capabilities across European languages. Establish model selection criteria based on clinical requirements, computational constraints, and regulatory compliance metrics.  **Task 5.2: VLM selection and adaptation (M1-M36)** – Lead: BSC/Participants: All  Evaluate and benchmark existing open-source VLMs for medical imaging integration with text data (section 1.2.2). Implement advanced multimodal fusion techniques and cross-modal attention mechanisms. Execute fine-tuning protocols for clinical imaging interpretation tasks including X-ray analysis, histopathological assessment, etc. Integrate uncertainty quantification for imaging-based diagnostic recommendations and establish validation protocols against expert clinical annotations.  **Task 5.4: Bias Detection and Fairness Evaluation Framework (M7-M48)** – Lead: RWTH/Participants: All  Implement comprehensive bias monitoring using [Fairlearn](https://fairlearn.org/) and [AI Fairness 360](https://ai-fairness-360.org/), measuring performance across demographic groups (age, gender, ethnicity, socioeconomic status). Develop automated bias detection mechanisms integrated into training pipelines with real-time monitoring capabilities. Execute adversarial debiasing techniques and demographic-aware data augmentation strategies. Establish fairness metrics including statistical parity, equalized odds, and calibration assessments. Create continuous evaluation protocols ensuring equitable performance across diverse patient populations throughout model lifecycle.  **Task 5.5: Robustness and Safety Validation (M7-M48)** – Lead: BSC/Participants: All  Implement NIST AI Risk Management Framework methodology for comprehensive trustworthiness assessment. Execute systematic robustness testing under adversarial conditions, prompt injection attacks, and emergent security risks. Establish safety assessment protocols using QUEST framework principles (Quality, Understanding, Expression, Safety, Trust). Implement TrustLLM benchmark evaluations across truthfulness, safety, fairness, robustness, privacy, and machine ethics dimensions. Create hallucination detection systems and inappropriate recommendation prevention mechanisms. Establish clinical validation protocols and human-in-the-loop feedback systems to guide iterative improvements in model tuning.  **Task 5.6: Agent-Model Integration Layer (M7-M48)** – Lead: Fraunhofer/Participants: All  Bridge the predictive AI models (developed in Tasks 5.1–5.5) with the agentic components defined in WP6 and WP8. The goal is to create a modular interface layer that allows agents to invoke models, interpret, and monitor the outputs of LLMs and VLMs within the agentic reasoning and decision-making workflows. Agents will also trigger fine-tuning based on clinical feedback. | |

|  |  |
| --- | --- |
| **Work package number** | 6 |
| **Work package title** | Reference Architecture and Interoperability |
| **Objectives**   * Deliver an EHDS-compliant, modular reference agentic architecture for Virtual Assistants (VAs) that supports cross-site federation, privacy-preserving analytics, and MCP-based agent orchestration. * Achieve semantic and syntactic interoperability across international data standards and terminologies (HL7/FHIR, DICOM, SNOMED CT, LOINC, ICD-10/11, ATC). * Provide federation and SPE services enabling cross-border collaboration across hospital sites. * Embed compliance-by-design (AIA, GDPR, MDR) into the architecture with automated audit trails, usage control, consent/legitimate interest governance, and runtime safeguards (policy enforcement points). * Provide an Agent–Model Integration Layer (AMIL) exposing MCP servers/tools to integrate WP5 models and WP8 VAs with traceable reasoning, uncertainty reporting, and explainability hooks. * Validate the reference implementation at pilot sites (with WP7 and WP8) and hand over a hardened, documented stack and playbooks to enable scale-up post-project. | |
| **Description of work**  **Task 6.1: Reference Architecture & Agent Integration (M1–M48)** - Lead: Fraunhofer/Participants: BSC, NTT DATA, RWTH  Design the EHDS-aligned reference architecture with layered views (infrastructure, data, services, agentic orchestration, governance) and a zero-trust security model (RBAC/ABAC, policy-as-code, provenance). Define MCP-based topology and the Agent–Model Integration Layer (AMIL). Produce interface contracts covering data space connectors (IDS-RAM compatible), usage control, and AMIL patterns.  **Task 6.2: Interoperability & Standards Integration (M3–M48)** - Lead: NTT DATA/Participants: Fraunhofer, BSC, RWTH, FPS  Implement FHIR profiles (R4/R5), terminology services and DICOM adapters; curate mapping pipelines with versioned ValueSets/CodeSystems and multilingual coverage. Design automatic conformance procedures and cross-border scenarios.  **Task 6.3: Federation Services & Compliance‑by‑Design (M4–M48)** - Lead: Fraunhofer/Participants: BSC, NTT DATA, RWTH, FPS, LIBRe  Deploy SPEs at pilot sites with hardened ingress/egress, disclosure checks, de‑identification, purpose binding and data lineage; integrate IDS connectors and policy engines. Provide federated services for cross‑site training/inference (with WP5), with identity/trust. Operationalise AIA high‑risk obligations and GDPR/MDR evidence collection.  **Task 6.4: Site Integrations, Validation & Handover (M18–M48)** - Lead: NTT DATA/Participants: Fraunhofer, BSC, RWTH, FPS  Implement the reference stack at clinical sites in an encapsulated environment. Prepare roadmap for complete clinical integration and consent management. | |

|  |  |
| --- | --- |
| **Work package number** | 7 |
| **Work package title** | Cloud Infrastructure and Continuous Integration |
| **Objectives**   * Provide secure, scalable cloud infrastructure that meets our requirements for data protection, regulatory compliance, and high availability. * Enable continuous integration and deployment (CI/CD) & MLOps through automated pipelines. * Ensure cybersecurity and regulatory compliance with GDPR, AIA, MDR and EHDS requirements through comprehensive security monitoring and audit frameworks. * Coordinate AI Factories deployment and utilization to leverage European supercomputing resources for training and inference of foundation models. | |
| **Description of work**  **Task 7.1: Cloud Infrastructure Setup** **& CI/CD (M7–M54)** - Lead: Fraunhofer/Participants: BSC, NTT Data, RWTH  Design and implement cloud-native architecture following microservices patterns optimized for healthcare AI workloads. Deploy Infrastructure as Code (IaC) using, e.g., Terraform and Kubernetes for reproducible and scalable deployments. Establish automated CI/CD pipelines incorporating MLOps best practices for healthcare AI model deployment. Implement container orchestration with Kubernetes for scalable and resilient service deployment. Establish development, staging, and production environments with isolation and security controls.  Coordinate deployments within the AI Factories (e.g., BSC, JUPITER): schedule release windows, resource reservations and change control; align execution with WP5, WP6 and WP8 components.  **Task 7.2: Security and Performance Monitoring (M7–M54)** - Lead: Fraunhofer/Participants: BSC, NTT Data, RWTH, TRI, LIBRe  Implement Zero Trust security architecture with identity and access management (IAM). Deploy comprehensive logging, monitoring, and alerting systems using Prometheus, Grafana, etc. Deploy vulnerability scanning and security incident response procedures. Establish backup, disaster recovery, and business continuity protocols. Establish audit-ready evidence collection for AIA/GDPR/MDR and operational logs/approvals in coordination with WP3.  **Task 7.3: Technology monitoring (M7–M48)** - Lead: Fraunhofer/Participants: BSC, NTT Data, RWTH  Continuously assess platform/tooling options and manage upgrades/migrations. Issue concise technology watch notes aligned to the project iteration cycles with deprecation guidance. | |

|  |  |
| --- | --- |
| **Work package number** | 8 |
| **Work package title** | Development and Evaluation of Virtual Assistants |
| **Objectives**   * Deliver user-centred, trustworthy clinical virtual assistants (VAs) in 3 medical fields (Rheumatology, Oncology and Periodontology), developed in two iterations. * Implement VAs reflecting user and stakeholder requirements captured in WP4, the architectural requirements of WP6, and built on top of the evaluated models produced in WP5, ensuring full alignment with the regulatory, ethical and trustworthiness requirements of WP3 and the data governance and FAIR-by-design practices of WP9. * Ensure clinical workflow integration, multilingual accessibility, and explainability; provide measurable improvements in usability (SUS), user experience (UEQ), and clinical utility indicators for each field. * Validate usability and accessibility (incl. WCAG 2.2 AA) in every medical field, with iterative improvements. | |
| **Description of work**  **Task 8.0: Cross-cutting coordination, integration & compliance (M10–M54)**. Lead: NTT Data/Participants: All  Coordinate VA specifications and integration patterns across the 3 medical fields; maintain alignment with WP4 requirements and WP5 model interfaces. Ensure Compliance-by-Design with WP3 (AIA/GDPR/MDR) and WP9 (FAIR, governance, SPE constraints) including audit-ready evidence and accessibility targets. Provide common UX patterns, multilingual support, and explainability components reusable across fields; oversee release iterations.  *Rheumatology (RA/SLE use cases). Lead: Fraunhofer/Participants: UDUS, UNIPI, UMF, KEM, empirica*  **Task 8.1: First prototype rheumatology VAs (M10–M18)**  Implement VA modules (HCP- and patient-facing) leveraging WP5 models and WP6 architectural requirements. Integrate PROMs-based monitoring, flare risk estimation, and guideline-conform care-plan suggestions (HITL).  **Task 8.2: Rheumatology VAs - First usability & accessibility validation (M18–M24)**  Conduct structured usability tests (SUS, UEQ) with clinicians and patients; execute accessibility audits vs. WCAG 2.2 AA. Collect HITL feedback and error taxonomy for model/VA refinement; prioritise updates for next version.  **Task 8.3: Final prototype rheumatology VAs (M24–M36)**  Implement prioritised improvements (bias/robustness fixes, UX enhancements, multilingual parity). Integrate uncertainty quantification visuals and safety checks; prepare workflow integration guides for sites.  **Task 8.4: Rheumatology VAs - Final usability & accessibility validation. Adoption preparation (M36–M54)**  Repeat usability/accessibility assessment post-Iteration 2; compare SUS/UEQ deltas; collect adoption blockers. Prepare field-specific user guides, training materials; contribute evidence to WP3/HTA and WP2 communication.  *Oncology (Prostate cancer use cases). Lead: BSC/Participants: VHIO, SOLTI, AOUI VR, RWTH, empirica*  **Task 8.5: First prototype oncology VAs (M10–M18)**  Implement HCP-facing VAs: (a) prognostic support at first-line therapy; (b) MTB/clinical-trial matching. Connect to WP5 models for structured info extraction and prognostic modelling; integrate trial knowledge bases.  **Task 8.6: Oncology VAs - First usability & accessibility validation (M18–M24)**  Conduct structured usability tests (SUS, UEQ) with clinicians and patients; execute accessibility audits vs. WCAG 2.2 AA. Collect HITL feedback and error taxonomy for model/VA refinement; prioritise updates for next version.  **Task 8.7: Final prototype oncology VAs (M24–M36)**  Refine prognostic VA and MTB assistant. Implement prioritised improvements (bias/robustness fixes, UX enhancements, multilingual parity). Integrate uncertainty quantification visuals and safety checks; prepare workflow integration guides for sites.  **Task 8.8: Oncology VAs - Final usability & accessibility validation. Adoption preparation (M36–M54)**  Repeat usability/accessibility assessment post-Iteration 2; compare SUS/UEQ deltas; collect adoption blockers. Prepare field-specific user guides, training materials; contribute evidence to WP3/HTA and WP2 communication.  *Periodontology (Periodontitis & peri-implantitis use cases). Lead: NTT Data/Participants: CHUL, AU, UGOT, UNIPI, Fraunhofer, RWTH, empirica*  **Task 8.9: First prototype periodontology VAs (M10–M18)**  Implement screening & chairside diagnostic VA (HCP-facing) and patient companion app for education and follow-up. Integrate imaging pipelines (where applicable), PROMs, and risk prediction. Connect to WP5 models for structured info extraction and prognostic modelling; integrate trial knowledge bases.  **Task 8.10: Periodontology VAs - First usability & accessibility validation (M18–M24)**  Conduct structured usability tests (SUS, UEQ) with clinicians and patients; execute accessibility audits vs. WCAG 2.2 AA. Collect HITL feedback and error taxonomy for model/VA refinement; prioritise updates for next version.  **Task 8.11: Final prototype periodontology VAs (M24–M36)**  Refine diagnostic suggestions, supportive-therapy interval personalisation. Implement prioritised improvements (bias/robustness fixes, UX enhancements, multilingual parity). Integrate uncertainty quantification visuals and safety checks; prepare workflow integration guides for sites.  **Task 8.12: Periodontology VAs - Final usability & accessibility validation. Adoption preparation (M36–M54)**  Repeat usability/accessibility assessment post-Iteration 2; compare SUS/UEQ deltas; collect adoption blockers. Prepare field-specific user guides, training materials; contribute evidence to WP3/HTA and WP2 communication. | |

|  |  |
| --- | --- |
| **Work package number** | 9 |
| **Work package title** | Data Management and Integration |
| **Objectives**   * Establish a regulatory-compliant, FAIR-by-design data lifecycle across all clinical sites, covering collection, curation, governance, security and lawful reuse. Operationalise FAIR principles with persistent identifiers, standardised metadata and terminology/ontology mappings to enable cross-site interoperability. * Deliver and maintain the project’s Data Management Plan (DMP) in line with official requirements. * Implement data governance and security controls (including SPEs) that support GDPR, AIA and MDR obligations and EHDS alignment. * Enable open science practices, including procedures for open access to publications, anonymised/synthetic datasets and software, with clear licences and reuse conditions. | |
| **Description of work**  **Task 9.1: Regulatory-compliant data collection and preprocessing (M1-M24)**. Lead: RWTH/Participants: All  Compile and preprocess structured and unstructured healthcare data (EHR, medical imaging, genomics, laboratory results, PROMs), together with best practices guidelines and references from clinical partners. Implement GDPR-by-design data processing with comprehensive privacy impact assessments and EHDS-compliant data handling procedures. Execute tokenization, normalization, de-identification, and multimodal alignment ensuring data standards. Establish QA protocols and validation frameworks for training dataset integrity. Create enhanced training datasets modified through interaction with agentic framework components. D9.1—3 input to WP5.  **Task 9.2: Data Management Plan (DMP). Data governance and security (M1–M54).** Lead: FPS/Participants: All  Draft, publish and maintain the consortium DMP per Horizon Europe guidance. Scope covers: data inventory (sources, formats, volumes), lawful bases & consent artefacts, roles and responsibilities, storage/backup, retention/archival, access procedures, repository selection, licenses, and reuse conditions. Design and operationalise access, sharing and protection policies; implement pseudonymisation/anonymisation pipelines within SPEs with audit trails&RBAC. Align with and monitor compliance with GDPR, AIA high-risk obligations and MDR requirements. Provide governance templates (DPIA templates, data-sharing agreements, access logs).  **Task 9.3: FAIR data implementation and interoperability (M6–M54).** Lead: RWTH /Participants: All  Operationalise FAIR via standardised metadata profiles, PIDs (e.g., DOIs), and ontology mappings. Maintain a federated catalogue for discoverability and reuse; validate interoperability via HL7/FHIR where applicable.  **Task 9.4: Open science enablement (M24–M36).** Lead: FPS/Participants: All  Promote open access to publications, anonymised datasets (when lawful) and selected software; define deposition procedures and documentation; support synthetic datasets for sharing. | |

### List of deliverables

| Deliv. # | Deliverable name | Short description | WP # | Short name of lead part. | Type | Diss. level | Deliv. Date |
| --- | --- | --- | --- | --- | --- | --- | --- |
| D1.1a,b | Project Management and QA Handbook | General description of the management infrastructure and project QA procedures | WP1 | Fraunhofer | R | SEN | M3, M27 |
| D1.2 | Risk Management Plan | Monitoring document of identified risks. Contingency plans in case a risk materializes. Updated with every periodic report to the EC | WP1 | Fraunhofer | R | SEN | M3 |
| D2.1 | Project website and social media channels | Project website and social media channels set up and findable | WP2 | empirica | DEC | PU | M3 |
| D2.2a,b | Communication, dissemination and outreach strategy | Stakeholder mapping and detailed communication and dissemination strategy, including KPIs (and updates) | WP2 | empirica | R | SEN | M27, M54 |
| D2.3a,b | Exploitation and sustainability plan | Outline of exploitable assets and plans for sustainable uptake (and updates) | WP2 | empirica | R | SEN | M27, M54 |
| D2.4a,b,c | Communication and dissemination activity report | Report about the communication and dissemination activities during the project | WP2 | empirica | R | SEN | M12, M27, M54 |
| D2.5a,b,c | Stakeholder engagement report | Report about the stakeholder engagement within the activities project | WP2 | empirica | R | SEN | M18, M36, M54 |
| D3.1 | Report on AI Adoption Practices | A stakeholder-aligned 5-page AI Adoption Practices Brief, including: A typology of current AI implementation practices. Examples illustrating effective integration. Key enablers and risks associated with adoption. A checklist for guiding actions to inform future AI governance and implementation strategies. Includes a Regulatory Gap Analysis | WP3 | TRI | R | PU | M6 |
| D3.2 | Ethical and Legal AI Framework (Preliminary) | This deliverable presents the Preliminary Ethical and Legal AI Framework, which provides an overview of the key ethical standards, rights, principles, and guidelines which will be adhered to and considered by the AURORA partners, with focus on AI principles and regulations. | WP3 | TRI | R | PU | M12 |
| D3.3 | Ethical and Legal AI Framework (Update) | Through conducting an integrated privacy, ethical, legal and social impact assessment, an updated version of the Ethical and Legal Framework will be created. The integrated impact assessment will function as a mechanism to identify emerging issues, implement mitigation strategies, and will focus on the ethical and legal requirements identified in the preliminary version of the Ethical and Legal AI Framework. | WP3 | TRI | R | PU | M36 |
| D3.4 | Ethical and Legal AI Framework (Final) | The final version of the Ethical and Legal AI Framework will be prepared through the integrated privacy, ethical, legal and social impact assessment. | WP3 | TRI | R | PU | M52 |
| D3.5 | Reflexivity Framework | Framework for reflexivity workshops within the consortium | WP3 | JU | R | PU | M6 |
| D3.6 | Reflexivity Workshop Reports | Reports on the reflexivity workshops with the consortium members | WP3 | JU | R | PU | M12, M24, M36, M48 |
| D3.7 | Media and Social Media Corpus on Trust in Healthcare AI | Report on the corpus of media and social media on healthcare AI | WP3 | JU | R | PU | M12 |
| D3.8 | Comparative Report on Discourses of Trust/Distrust | Comparative analysis of discourses of trust and distrust in healthcare and AI across at least ten European countries | WP3 | JU | R | PU | M18 |
| D3.9 | Understanding trust and distrust in AI-assisted diagnosis | Final report summarizing the results of co-design with patients and healthcare professionals in specific case studies | WP3 | JU | R | PU | M44 |
| D3.10 | Recommendations for Trust-Building in GenAI Platform in specific case studies | Recommendations for further works on trust in AI diagnosis | WP3 | JU | R | PU | M48 |
| D3.11 | Final Integration Report on incorporating reflexivity and understanding of trust into platform design | Final report integrating the results of tasks 3.4, 3.5, 3.6 on trust in healthcare AI and reflexive deisgn. | WP3 | JU | R | PU | M50 |
| D3.12 | Legal and Regulatory Conformity Report (Preliminary) | Overview of the healthcare, privacy and security requirements and standards to be adhered to and considered by the AURORA partners while developing project tools and services | WP3 | LIBRe | R | PU | M10 |
| D3.13 | Legal and Regulatory Conformity Report (Update) | Report on project tools and services' adherence to legal and regulatory assessments (interim results) | WP3 | LIBRe | R | PU | M34 |
| D3.14 | Legal and Regulatory Conformity Report (Final) | Report on project tools and services' adherence to legal and regulatory assessments (final results) | WP3 | LIBRe | R | PU | M50 |
| D3.15 | Regulatory testing and experimentation in healthcare AI Report (Preliminary) | Report on project achievements under T3.8 by M24, including the progress achieved liaising with competent authorities responsible for operating the AI regulatory sandboxes, assessing the trustworthiness of benchmarks from an applied and regulatory perspective, and interim feedback received by stakeholders | WP3 | LIBRe | R | PU | M24 |
| D3.16 | Regulatory testing and experimentation in healthcare AI Report (Final) | Report on the final outcomes of T3.8, incl. all activities performed and results achieved. | WP3 | LIBRe | R | PU | M48 |
| D3.17 | HTA Readiness Package Rheumatology | Decision-grade HTA dossier (value proposition, endpoints & minimal dataset, effectiveness/safety & usability/PROs/PREMs, resource use, brief budget-impact), with full requirement→evidence traceability | WP3 | FPS | R | SEN | M54 |
| D3.18 | HTA Readiness Package Oncology | Decision-grade HTA dossier (value proposition, endpoints & minimal dataset, effectiveness/safety & usability/PROs/PREMs, resource use, brief budget-impact), with full requirement→evidence traceability | WP3 | FPS | R | SEN | M54 |
| D3.19 | HTA Readiness Package Periodontology | Decision-grade HTA dossier (value proposition, endpoints & minimal dataset, effectiveness/safety & usability/PROs/PREMs, resource use, brief budget-impact), with full requirement→evidence traceability | WP3 | FPS | R | SEN | M54 |
| D4.1 | Preliminary User & Stakeholder Requirements | Insights, personas, journeys, and acceptance criteria to steer WP5/WP8. | WP4 | Fraunhofer | R | PU | M6 |
| D4.2 | Consolidated User & Stakeholder Requirements | Traceable specifications handed over to WP5 (models) and WP8 (VAs). | WP4 | Fraunhofer | R | PU | M12 |
| D4.3 | RHE: Study initiation package | Registration number (WHO-criteria registry), final approved protocol, regulatory/ethics approvals enabling first enrolment (due before enrolment). | WP4 | UDUS | R | SEN | M18 |
| D4.4 | RHE: Midterm recruitment report | At 50% recruitment: participants per site, issues, mitigation measures (implemented/planned). | WP4 | UDUS | R | SEN | M29 |
| D4.5 | RHE: Results-posting status report | Status of summary results posting in the applicable registry(ies). | WP4 | UDUS | R | SEN | M54 |
| D4.6 | ONC: Study initiation package | Registration number (WHO-criteria registry), final approved protocol, regulatory/ethics approvals enabling first enrolment (due before enrolment). | WP4 | VHIO | R | SEN | M18 |
| D4.7 | ONC: Midterm recruitment report | At 50% recruitment: participants per site, issues, mitigation measures (implemented/planned). | WP4 | VHIO | R | SEN | M29 |
| D4.8 | ONC: Results-posting status report | Status of summary results posting in the applicable registry(ies). | WP4 | VHIO | R | SEN | M54 |
| D4.9 | PER: Study initiation package | Registration number (WHO-criteria registry), final approved protocol, regulatory/ethics approvals enabling first enrolment (due before enrolment). | WP4 | CHUL | R | SEN | M18 |
| D4.10 | PER: Midterm recruitment report | At 50% recruitment: participants per site, issues, mitigation measures (implemented/planned). | WP4 | CHUL | R | SEN | M29 |
| D4.11 | PER: Results-posting status report | Status of summary results posting in the applicable registry(ies). | WP4 | CHUL | R | SEN | M54 |
| D5.1 | Model evaluation & benchmarking protocol (v1) | KPIs, datasets/benchmarks, metrics, acceptance thresholds; links to WP3/WP4. | WP5 | BSC | R | SEN | M4 |
| D5.2 | Initial model selection & preliminary fine-tuning report | Comparative assessment of candidate LLMs/VLMs; early fine-tuning on curated clinical corpora; go/no-go gates per use case. | WP5 | Fraunhofer | R | SEN | M6 |
| D5.3 | Regulatory-by-design training pipeline (v1) | Implemented training/finetune pipeline with AIA/GDPR/MDR controls (data lineage, consent artifacts, audit hooks), ready for deployment. | WP5 | Fraunhofer | OTHER | SEN | M9 |
| D5.4 | Model Iteration 1 package (LLM+VLM v1) | Deployed v1 models with uncertainty quantification & calibration, model cards, datasheets, bias dashboards, and agent adapters for VA prototyping. | WP5 | BSC | DEM | PU | M12 |
| D5.5 | Bias & fairness evaluation toolkit (v1) + baseline | Tooling and results across protected groups; metrics (calibration) and mitigation catalogue integrated in CI. | WP5 | RWTH | OTHER | PU | M18 |
| D5.6 | Model selection and validation report (v1) | Per-use-case performance vs. thresholds; HITL protocols; decision records for selected models. (Delivers Mi5 evidence) | WP5 | BSC | R | SEN | M27 |
| D5.7 | Robustness and safety validation report (v1) | NIST AI RMF-based stress tests, red-teaming, hallucination/unsafe-output guards; incident playbooks. | WP5 | BSC | R | SEN | M27 |
| D5.8 | Model Iteration 2 package (LLM+VLM v2) | Second iteration with improved multimodal fusion & multilingual parity, reduced bias, tighter guardrails; Agent-Model Integration Layer v2. | WP5 | BSC | DEM | PU | M36 |
| D5.9 | Model repository handover & open-source release plans | Release-candidate weights/artifacts, APIs, versioning, licensing & openness matrix; hand-over instructions to WP6/8. | WP5 | BSC | R | PU | M39 |
| D5.10 | Standard Operating Procedures (SOPs) for continuous bias/safety monitoring | Operating procedures + dashboards for runtime monitoring, rollback/retrain triggers, and governance hooks for runtime. | WP5 | RWTH | R | PU | M39 |
| D6.1 | Reference Architecture v1 | First iteration specification & blueprint incl. MCP-based agent orchestration and security model. | WP6 | Fraunhofer | R | PU | M15 |
| D6.2 | Interoperability Profiles & Conformance Suite v1 | Interoperability profiles, CodeSystems, ValueSets & automated conformance tests. | WP6 | NTT DATA | OTHER | PU | M18 |
| D6.3 | Site Deployment Package v1 | Hardened stack, playbooks, AMIL adapters; deployed at pilot sites (v1). | WP6 | NTT DATA | DEM | PU | M18 |
| D6.4 | Federation & SPE Services v1 | Federated training/inference services with IDS connectors, purpose binding, disclosure checks. | WP6 | Fraunhofer | OTHER | SEN | M24 |
| D6.5 | Interoperability Framework Update & Cross-border Validation | Results from cross-site tests; gaps & fixes; v2 profiles roadmap. | WP6 | NTT DATA | R | SEN | M36 |
| D6.6 | Reference Architecture v2 | Second iteration specification with lessons learned, scalability & governance updates. | WP6 | Fraunhofer | R | PU | M42 |
| D6.7 | EHDS/FAIR Compliance & Audit Evidence Pack | Evidence logs, policies, and checklists covering AIA/GDPR/MDR & FAIR. | WP6 | RWTH | R | SEN | M42 |
| D6.8 | Site Deployment Package v2 | Updated stack deployed at sites + runbooks and ops handover. | WP6 | NTT DATA | DEM | SEN | M48 |
| D7.1 | Cloud & CI/CD baseline (v1) | IaC-provisioned K8s stacks (DEV/STAGE/PROD) and CI/CD for WP5 model builds & WP6 services; enables Mi3 and D5.4/D6.1. | WP7 | Fraunhofer | DEM | SEN | M12 |
| D7.2 | Security & observability (v1) | Zero-Trust IAM, logging/alerting, vuln scans, initial AIA/GDPR/MDR evidence capture. | WP7 | Fraunhofer | OTHER | SEN | M18 |
| D7.3 | AI Factories & federation ops enablement | Pipelines/schedulers for BSC/JAIF training & inference, performance baseline, site SRE runbooks. | WP7 | Fraunhofer | OTHER | SEN | M24 |
| D7.4 | Platform scaling & migration (v2) | Hardened platform v2 with upgrade/migration playbooks and capacity tests; aligns with D5.8/D6.5 and Mi6. | WP7 | Fraunhofer | DEM | SEN | M36 |
| D7.5 | Compliance & security (v2). Audit pack | Enhanced monitoring, incident playbooks, and compiled audit evidence. | WP7 | Fraunhofer | R | SEN | M42 |
| D7.6 | Final ops handover & sustainability plan | Ops handover, de-risking & cost-efficiency roadmap for post-project operations. | WP7 | Fraunhofer | R | SEN | M54 |
| D8.1 | VAs design and compliance specifications | Functional specs, interfaces, and compliance criteria derived from WP4/WP3; cross-field patterns for UX, explainability, accessibility. | WP8 | NTT DATA | DEM | SEN | M12 |
| D8.2 | First VA prototypes: Rheumatology, Oncology, Periodontology | First integrated VA prototypes per field aligned with Mi4; deployed in test/sandbox across pilot sites. | WP8 | NTT DATA | DEM | SEN | M18 |
| D8.3 | Rheumatology VAs: First Usability & Accessibility Report | SUS/UEQ results, workflow fit, and WCAG 2.2 AA conformance findings; backlog for iteration 2. | WP8 | Fraunhofer | R | SEN | M24 |
| D8.4 | Oncology VAs: First Usability & Accessibility Report | SUS/UEQ results, workflow fit, and WCAG 2.2 AA conformance findings; backlog for iteration 2. | WP8 | RWTH | R | SEN | M24 |
| D8.5 | Periodontology VAs: First Usability & Accessibility Report | SUS/UEQ results, workflow fit, and WCAG 2.2 AA conformance findings; backlog for iteration 2. | WP8 | NTT DATA | R | SEN | M24 |
| D8.6 | Final VA prototypes: Rheumatology, Oncology, Periodontology | Second-generation integrated releases with refined UX, explainability and safeguards; ready for workflow pilots. | WP8 | NTT DATA | DEM | PU | M36 |
| D8.7 | Rheumatology VAs: Clinical evaluation summary | Clinical performance and adoption metrics; safety/incident overview; recommendations. | WP8 | UDUS | R | SEN | M42 |
| D8.8 | Oncology VAs: Clinical evaluation summary | Clinical performance and adoption metrics; safety/incident overview; recommendations. | WP8 | VHIO | R | SEN | M42 |
| D8.9 | Periodontology VAs: Clinical evaluation summary | Clinical performance and adoption metrics; safety/incident overview; recommendations. | WP8 | CHUL | R | SEN | M42 |
| D8.10 | Rheumatology VAs: Final Usability & Accessibility Report | Field-specific ACR documenting accessibility tests and remediation status. | WP8 | Fraunhofer | R | PU | M48 |
| D8.11 | Oncology VAs: Final Usability & Accessibility Report | Field-specific ACR documenting accessibility tests and remediation status. | WP8 | BSC | R | PU | M48 |
| D8.12 | Periodontology VAs: Final Usability & Accessibility Report | Field-specific ACR documenting accessibility tests and remediation status. | WP8 | UDUS, VHIO, CHUL | R | PU | M48 |
| D8.13 | Final clinical validation & adoption playbook | Consolidated clinical validation results and an adoption playbook per field (training, change mgmt, governance hooks). | WP8 | UDUS, VHIO, CHUL | R | SEN | M54 |
| D8.14 | Human-in-the-Loop evaluation dataset (anonymised) | Anonymised usability & interaction dataset and instruments; release subject to ethics and governance approvals. | WP8 | UDUS, VHIO, CHUL | DATA | SEN | M54 |
| D9.1 | Initial regulatory-compliant training datasets | Initial datasets for AI models training | WP9 | RWTH | DATA | SEN | M6 |
| D9.2 | Intermediate regulatory-compliant training datasets | Intermediate datasets for AI models training | WP9 | RWTH | DATA | SEN | M18 |
| D9.3 | Final regulatory-compliant training datasets | Final datasets for AI models training | WP9 | RWTH | DATA | PU | M39 |
| D9.4 | Data Management Plan (v1) | Data Management Plan per HE guidelines | WP9 | FPS | DMP | PU | M6 |
| D9.5 | Final Data Management Plan | Final update of the Data Management Plan | WP9 | FPS | DMP | PU | M54 |
| D9.6 | FAIR Compliance Requirements & Implementation Guide v1 | Documentation of FAIR requirements and practical checklists for partners. | WP9 | FPS | R | SEN | M12 |
| D9.7 | FAIR Compliance Requirements & Implementation Guide v2 | Final documentation of FAIR requirements and practical checklists for partners. | WP9 | FPS | R | SEN | M54 |
| D9.8 | Open Science Plan & Procedures | Plan procedures for open access publications & dataset/software deposition. | WP9 | FPS | R | SEN | M36 |

Table 4. List of Deliverables.

### List of milestones

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| Milestone number | Milestone name | Related WPs | Due date (in month) | Means of verification |
| Mi1 | Project management infrastructure and ethical framework established | WP1, WP2, WP3, WP4 | M3 | Management tools deployed and operational; communication channels established; D2.1; ethical approval obtained from all clinical sites; ethical/legal/SSH framework document |
| Mi2 | Initial AI models fine-tuning and Data Management Plan | WP3, WP4, WP5, WP9 | M6 | Preliminary fine-tuning results for at least 3 foundation models documented; user requirements report (D4.1); DMP |
| Mi3 | EHDS-Compliant Cloud Infrastructure and Federated Learning Platform | WP6, WP7, WP9 | M12 | Secure Processing Environment (SPE) processes operational; federated infrastructure tested with synthetic data; EHDS initial compliance framework prepared |
| Mi4 | First stable VA prototypes | WP5, WP6, WP8 | M18 | At least 3 functional VA prototypes demonstrated (one per clinical use case); agentic architecture with MCP integration validated; interoperability testing completed with ≥4 healthcare standards |
| Mi5 | Clinical use case model selection and validation | WP4, WP5, WP8 | M27 | Final model selection completed for all three clinical use cases based on selected benchmarks; clinical validation protocols established; initial regulatory documentation |
| Mi6 | Integrated VAs Platform with Clinical Workflow Integration | WP4, WP5, WP6, WP7, WP8 | M36 | Second-generation prototypes integrated into clinical workflows at partner sites; usability testing results available; |
| Mi7 | Final Model Repository and Reference Architecture Publication | WP5, WP6, WP8 | M48 | Complete fine-tuned model repository published with open-source licensing; reference architecture documentation released; regulatory compliance certification pathway established; |
| Mi8 | End of the project | WP1, WP2, WP3, WP4, WP5, WP6, WP7, WP8, WP9 | M54 | Final project report delivered; impact assessment demonstrating improved clinical outcomes completed; all VA demonstrators available; final conference held; sustainability and exploitation plans available |

Table 5. List of milestones.

### Critical risks for implementation

Comprehensive risk management ensures patient safety, data protection and privacy, together with regulatory compliance throughout the project lifecycle. The table below presents a compilation of risks for our proposal, which includes the standard management risks for projects of this type. The table includes a likelihood estimation and an impact assessment, together with the proposed mitigation measures.

| Description of risk[[2]](#footnote-3) | WPs | Proposed risk-mitigation measures |
| --- | --- | --- |
| **Underestimation of project duration/resources and efforts.**  Complex AI development cycles, regulatory compliance requirements, and multi-stakeholder coordination may lead to significant underestimation of time and resources needed, particularly given the novel challenges of generative AI in healthcare. *(Possible; Low)* | All | **Enhanced monitoring framework:** Implement Agile project management with monthly sprint reviews and quarterly stakeholder assessments. Establish dedicated AI development timeline tracking with buffer allocation (20% contingency) for model training and validation phases. **Expertise leverage:** Project coordinator has extensive experience managing multinational research projects and will establish specialized monitoring mechanisms for development milestones. Deploy automated project tracking tools with resource allocation monitoring. **Risk mitigation:** Implement parallel development tracks for critical components and establish decision points at key milestones. |
| **Delays in achieving deliverables and milestones.**  AI model development, regulatory compliance processes, and multi-site clinical validation may experience significant delays due to technical challenges, regulatory changes, or clinical site coordination issues. *(Possible; Low)* | All | **Adaptive planning strategy:** Implement rolling wave planning with quarterly reviews and adaptive scope management. Establish parallel validation tracks across multiple clinical sites to reduce dependency risks. **Contingency protocols:** Develop contingency plans for each critical milestone, including alternative technical approaches. **Early warning system:** Milestone tracking with automated alerting for potential delays. Partners’ proven track record in managing complex multi-site clinical studies provides robust foundation for risk mitigation. |
| **Enhanced data availability/quality/completeness challenges for AI**.  AI models require high-quality, diverse, and representative datasets. Healthcare data fragmentation, privacy constraints, and bias in historical data may impact model development and validation beyond traditional data management challenges. *(Possible; Medium)* | All | **Comprehensive data strategy:** Implement data quality assessment pipelines with monitoring of data completeness, bias detection, and representativeness metrics. **Multi-source approach:** Establish partnerships with diverse clinical sites across different regions to ensure demographic and clinical diversity. Use of open data available from previous projects. **Technical solutions:** Implement privacy-preserving methods whenever necessary and establish clear data lineage tracking. Partners’ extensive experience in healthcare data curation will be augmented with data governance frameworks. **Regulatory compliance:** Ensure full GDPR and AIA compliance with clear data processing agreements and patient consent frameworks. **Technical assurance:** Deploy advanced privacy-preserving technologies to address data sharing concerns. |
| **Communication problems among partners.**  Complex development requires intensive collaboration between technical experts, clinical specialists, regulatory professionals, and healthcare stakeholders, increasing communication complexity beyond traditional research projects. *(Unlikely; Low)* | All | **Structured communication framework:** Establish specialized communication channels for different expertise domains (technical, clinical, regulatory, ethical). Implement periodic meetings with rotating leadership. **Digital collaboration platform:** Deploy integrated project management and communication tools with specific documentation repositories and decision tracking. **Conflict resolution:** Project coordinator will establish clear escalation procedures and maintain bilateral relationship management protocols. |
| **Risk of “dropout” of key project leaders.**  Loss of key AI researchers, clinical champions, or regulatory experts could significantly impact project continuity and knowledge retention. *(Possible; Medium)* | All | **Enhanced succession planning:** Define primary and secondary deputies for all critical roles, with mandatory knowledge transfer protocols and comprehensive documentation requirements. **Knowledge management:** Implement knowledge management systems with detailed model development documentation, decision rationales, and technical specifications. **Retention strategies:** Establish competitive retention packages, professional development opportunities, and clear intellectual property sharing agreements. **Rapid replacement:** Maintain active relationships with talent networks and establish fast-track hiring protocols for critical skill replacement. |
| **Target technologies will change rapidly making project objectives obsolete.**  Generative AI field is evolving extremely rapidly with new models, techniques, and regulatory requirements emerging continuously. Project objectives may become outdated during the 3- or 4-year project timeline. *(Likely; Medium)* | All | **Adaptive technology strategy:** Implement modular architecture allowing model updates and technology evolution. Establish periodic technology landscape reviews with leading research institutions and industry partners. **Future-proofing approach:** Focus on generalizable frameworks rather than specific model implementations. **Regulatory monitoring:** Maintain continuous engagement with AIA implementation committees and regulatory bodies for early awareness of requirement changes. **Innovation pipeline:** Partners’ active participation in AI research communities and standardization bodies ensures early access to emerging technologies and best practices. |
| **Pilot site implementation challenges.**  Deploying AI systems across diverse healthcare environments with varying IT infrastructure, clinical workflows, and staff capabilities may present significant integration and adoption challenges. *(Possible; Medium)* | All | **Comprehensive site preparation:** Conduct detailed technical and organizational readiness assessments for each pilot site before deployment. Implement standardized deployment frameworks with site-specific customization capabilities. **Local partnership strategy:** Establish dedicated local implementation teams with clinical champions and technical support specialists at each site. **Phased deployment:** Implement staged rollout approach with intensive monitoring and rapid issue resolution protocols. **Infrastructure support:** Partners’ extensive experience in multi-site clinical implementations provides proven methodologies for successful deployment across diverse healthcare environments. |
| **End-user (clinicians and patients) recruitment challenges for validation studies**.  Recruiting end users for technology validation may be challenging due to concerns about AI decision-making, data privacy, or digital health literacy. *(Possible; Medium)* | All | **Enhanced recruitment strategy:** Implement comprehensive engagement programs with clear communication about AI benefits and privacy protections. Develop culturally appropriate recruitment materials and multilingual support for diverse populations. |
| **AI Model Performance Degradation and Bias.**  AI models may exhibit performance decay over time or manifest algorithmic bias, leading to inaccurate recommendations or discriminatory outcomes. This is particularly critical for generative AI models that may “hallucinate” or produce biased outputs affecting patient safety. *(Possible; High)* | All | **Continuous monitoring framework:** Establish performance monitoring with predefined KPIs for model accuracy, fairness metrics, and bias detection across demographic groups. Implement diverse validation datasets. **Immediate response:** Deploy automatic model rollback protocols, retraining procedures with augmented datasets, and escalation to AI governance committee. **Ongoing validation:** Implement continuous validation against established clinical guidelines with expert review loops and confidence scoring for AI outputs. **Human oversight mandate:** Require clinical expert approval for AI-generated recommendations before clinical application. |
| **Non-Compliance with AIA.**  Failure to comply with AIA requirements for high-risk AI systems in healthcare, including risk management, data governance, transparency, and human oversight obligations. *(Unlikely; High)* | All | **Comprehensive compliance framework:** Establish dedicated AIA regulatory framework. Implement risk management systems. **Continuous compliance:** Conduct compliance audits and establish clear human oversight protocols. **Red-teaming protocols:** Conduct adversarial testing and red-teaming exercises as required by AIA. |
| **Cybersecurity and AI-Specific Security Threats.**  Healthcare systems face enhanced cybersecurity risks including model poisoning, adversarial attacks, data breaches, and potential manipulation of decision-making processes, with severe implications for safety and GDPR compliance. *(Unlikely; High)* | All | **Comprehensive AI security framework:** Implement zero-trust architecture with end-to-end encryption and AI-specific security monitoring including model poisoning detection and adversarial attack prevention. **Advanced privacy protection:** Deploy privacy-preserving techniques and differential privacy for sensitive healthcare data. **Regular assessment:** Conduct periodic penetration testing and security audits. |

Table 6. Critical risks for implementation.

## Capacity of participants and consortium as a whole

The AURORA consortium represents a strategically designed interdisciplinary partnership that exemplifies excellence in healthcare AI research. Our **19-partner consortium across 10 EU countries** demonstrates an optimal architecture for complex healthcare AI projects. It embodies best practices for interdisciplinary healthcare AI research, with **a high percentage representation from social sciences, humanities, and regulatory domains** alongside technical and clinical expertise. Our partnership structure addresses the three critical success factors identified in recent research: communication excellence, trust-building capabilities, and collaborative integration through carefully designed governance and collaborative frameworks.

AURORA integrates expertise from computer science, clinical medicine, regulatory affairs, ethics, and health technology assessment to ensure comprehensive development and validation: **Computer Science and AI Engineering** contribute advanced machine learning methodologies, federated learning architectures, and privacy-preserving technologies; **Clinical Medicine** provides domain expertise for use case definition, clinical validation protocols, and outcome measurement; **Regulatory Affairs** ensures compliance strategy development and regulatory pathway navigation; **Ethics** guides ethical framework development and stakeholder engagement protocols; **Health Technology Assessment** contributes health economics analysis and implementation science methodologies. Cross-disciplinary integration occurs through methodology review meetings, stakeholder workshops, and advisory board reviews ensuring methodological coherence and scientific rigor.

![](data:image/jpeg;base64...)**Technical AI Leadership and Innovation**

**Fraunhofer (Coordinator)** brings years of applied research excellence with specific expertise in healthcare interoperability, AI applications, and large-scale project coordination. Fraunhofer FIT’s Digital Health Department provides experience in data spaces, healthcare standards and terminologies and interoperability compliance frameworks, and has successfully coordinated many international healthcare technology projects. **BSC** hosts the BSC AI Factory (EuroHPC-JU) and brings expertise in advanced computing solutions for clinical applications. **NTT Data** brings worldwide IT leadership in healthcare with direct experience in EHDS infrastructure development and interoperability standards. **RWTH** contributes cutting-edge AI research capabilities and serves as liaison to the Jülich AI Factory (EuroHPC-JU), providing access to state-of-the-art computing infrastructures.

**Clinical Excellence and Domain Knowledge**

Our clinical partners cover the complete spectrum of the three targeted use cases with proven expertise in AI integration. **CHUL, AU, UGOT** and **UNIPI** contribute specialized expertise in periodontitis. **UDUS** and **UNIPI** provide expertise in rheumatoid arthritis. **VHIO, AOUI VR** and **SOLTI** provide oncology expertise for prostate cancer use cases.

**Social Sciences, Humanities, and Regulatory Integration**

We follow an environmental humanities model for genuine interdisciplinary collaboration. **TRI** provides specialized regulatory expertise for AI ethics and compliance frameworks. **JU** provides dedicated SSH expertise in technology assessment and AI ethics in healthcare, ensuring co-definition of research problems from social science perspectives. **LIBRe** contributes specialized legal expertise in AI applications and data protection. **empirica** brings proven dissemination and communication strategies with different stakeholder groups, including patients, clinicians, and health authorities.Finally, **FPS** will contribute to the project as a Health Authority covering the HTA aspects of our developments and collaborate with the integration of regulatory aspects of the project developments.

### Summary of staff effort

Table 7 shows a list of efforts per partner and work package.

| # | Part. Short Name | WP1 | WP2 | WP3 | WP4 | WP5 | WP6 | WP7 | WP8 | WP9 | Total PM |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **1** | **Fraunhofer** | 24 | 12 | 12 | 4 | 20 | 24 | 24 | 18 | 12 | **150** |
| **2** | **BSC** | 2 | 2 | 6 | 6 | 33 | 6 | 18 | 6 | 2 | **81** |
| **3** | **CHUL** | 2 | 6 | 6 | 52 | 2 | 0 | 2 | 9 | 6 | **85** |
| **4** | **NTT DATA** | 2 | 6 | 2 | 5 | 23 | 22 | 8 | 25 | 2 | **95** |
| **5** | **UDUS** | 2 | 6 | 6 | 44 | 2 | 0 | 3 | 9 | 6 | **78** |
| **6** | **VHIO** | 2 | 6 | 8 | 55 | 22 | 0 | 0 | 9 | 6 | **108** |
| **7** | **AU** | 2 | 2 | 6 | 24 | 2 | 0 | 0 | 6 | 6 | **48** |
| **8** | **UNIPI** | 2 | 2 | 6 | 48 | 2 | 0 | 3 | 6 | 6 | **75** |
| **9** | **UGOT** | 2 | 2 | 6 | 24 | 2 | 0 | 2 | 6 | 6 | **50** |
| **10** | **TRI** | 2 | 2 | 30 | 6 | 12 | 1 | 1 | 2 | 6 | **62** |
| **11** | **UJ** | 2 | 6 | 28 | 3 | 7 | 0 | 0 | 2 | 4 | **52** |
| **12** | **Empirica** | 2 | 30 | 6 | 10 | 2 | 0 | 0 | 6 | 2 | **58** |
| **13** | **RWTH** | 2 | 2 | 6 | 3 | 18 | 18 | 10 | 6 | 12 | **77** |
| **14** | **AOUI VR** | 2 | 2 | 6 | 23 | 2 | 0 | 0 | 6 | 6 | **47** |
| **15** | **FPS** | 2 | 2 | 18 | 3 | 18 | 6 | 0 | 3 | 24 | **76** |
| **16** | **SOLTI** | 2 | 2 | 6 | 54 | 2 | 0 | 0 | 3 | 6 | **75** |
| **17** | **LIBRe** | 2 | 2 | 28 | 2 | 8 | 2 | 2 | 2 | 4 | **52** |
| **18** | **UMF Cluj** | 2 | 2 | 2 | 26 | 2 | 0 | 2 | 3 | 3 | **42** |
| **19** | **KEM** | 2 | 2 | 6 | 28 | 2 | 0 | 3 | 3 | 6 | **52** |
| Total PMs | | 60 | 96 | 194 | 420 | 181 | 79 | 78 | 130 | 125 | 1363 |

Table 7. Summary of staff effort.

### Subcontracting costs items

|  |  |  |
| --- | --- | --- |
| 7/AU | | |
|  | **Cost (€)** | **Description of tasks and justification** |
| **Subcontracting** | 515,000 € | Proteomics results are crucial for the periodontology clinical studies in the project. This analysis is realised by an external service. The cost for this work is calculated for 1,000 samples. |

Table 8. Subcontracting costs items (AU).

|  |  |  |
| --- | --- | --- |
| 12/empirica | | |
|  | **Cost (€)** | **Description of tasks and justification** |
| **Subcontracting** | 30,000 € | Costs related to the activities of the External Advisory Board of the project (travel & subsistence, allowances, etc.). |

Table 9. Subcontracting costs items (empirica).

|  |  |  |
| --- | --- | --- |
| 14/AOUI VR | | |
|  | **Cost (€)** | **Description of tasks and justification** |
| **Subcontracting** | 15,000 € | Support service analysing clinical data collected during the project, with proven experience in managing data from complex clinical trials. |

Table 10. Subcontracting costs items (AOUI VR).

|  |  |  |
| --- | --- | --- |
| 16/SOLTI | | |
|  | **Cost (€)** | **Description of tasks and justification** |
| **Subcontracting** | 100.290 € | For the prospective study: logistic of samples and kits provision (Spanish vendor) and blood sample analysis (vendor in the US) |

Table 11. Subcontracting costs items (SOLTI).

### Purchase costs items (travel and subsistence, equipment and other goods, works and services)

|  |  |  |
| --- | --- | --- |
| 4/NTT Data | | |
|  | **Cost (€)** | **Justification** |
| **Travel and subsistence** | 14,000 € | Travel costs related to the general activities of the project (Consortium meetings, reviews, conferences, etc.) |
| **Equipment** | 60,000 € | Server infrastructure to host virtual machines for the applications of the project; especially in WP7 |
| **Remaining purchase costs (<15% of pers. Costs)** | 4,000 € | Audit and other costs |
| **Total** | 78.000 € |  |

Table 12. Purchase costs items (travel and subsistence, equipment and other goods, works and services) (NTT Data).

|  |  |  |
| --- | --- | --- |
| 6/VHIO | | |
|  | **Cost (€)** | **Justification** |
| **Travel and subsistence** | 14,000 € | Travel costs related to the general activities of the project (Consortium meetings, reviews, conferences, etc.) |
| **Equipment** | 10,000 € | Server infrastructure to host virtual machines for the applications of the project |
| **Other goods, works and services** | 129,640 € | Sample preparation (histopathology, DNA extraction, library preparation, NGS sequencing) and analysis |
| **Remaining purchase costs (<15% of pers. Costs)** | 4,000 € | Audit and other costs |
| **Total** | 157.640 € |  |

Table 13. Purchase costs items (travel and subsistence, equipment and other goods, works and services) (VHIO).

### Other costs categories items (e.g., internally invoiced goods and services)

|  |  |  |
| --- | --- | --- |
| 10/TRI | | |
|  | **Cost (€)** | **Description of tasks and justification** |
| **Internally invoiced goods & services** | 38,400 € | STRIAD AI Assurance Licence Fee (annual fee of 9,600 €) |

Table 14. internally invoiced goods and services (TRI).

### In-kind contributions provided by third parties

We include here some estimations of the usage of computing time and services from the AI-Factories.

| AURORA Consortium | | | |
| --- | --- | --- | --- |
| **Third party name** | **Category** | **Cost (€)** | **Justification** |
| BSC AI Factory | Equipment  Consultancy | XXX € | **Model Development Services** (data transfer, storage, and management; foundation model catalog & hosting; model derivation and fine-tuning; model performance improvement). **Productisation Services** (model benchmarking & validation; model deployment; monitoring and performance tracking; legal assessment for ai products). **HPC Optimization Services** (first-level support; HPC deployment and monitoring; parallelisation of training and inference; reduction of memory usage). Required for WP4, WP5, WP6 & WP7 activities across all 3 clinical use cases. |
| JUPITER AI Factory (JAIF) | Equipment  Consultancy | XXX € | **Model Development Services** (data transfer, storage, and management; foundation model catalog & hosting; model derivation and fine-tuning; model performance improvement). **Productisation Services** (model benchmarking & validation; model deployment; monitoring and performance tracking; legal assessment for ai products). **HPC Optimization Services** (first-level support; HPC deployment and monitoring; parallelisation of training and inference; reduction of memory usage). Required for WP4, WP5, WP6 & WP7 activities across all 3 clinical use cases. |

Table 15. In-kind contributions provided by third parties.

# Appendix A: List of Acronyms

|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| |  |  | | --- | --- | | AI | Artificial Intelligence | | AIA | AI Act | | AUC | Area Under Curve | | EHDS | European Health Data Space | | EHR | Electronic Health Record | | GenAI | Generative AI | | GDPR | General Data Protection Regulation | | HTA | Health Technology Assessment | | HITL | Human-in-the-Loop | | IDS | International Data Spaces | | IP | Intellectual Property | | LLM | Large Language Model | | MCP | Model Context Protocol | | PHI/PII | Protected Health Information/Personally Identifiable Information | | |  |  | | --- | --- | | PROM | Patient-Reported Outcome Measure | | RA | Rheumatoid Arthritis | | RAG | Retrieval-Augmented Generation | | RLHF | Reinforcement Learning from Human Feedback | | ROC | Receiver Operating Characteristic | | SLE | Systemic Lupus Erythematosus | | SPE | Secure Processing Environment | | SUS | System Usability Scale | | SSH | Social Sciences and Humanities | | UEQ | User Experience Questionnaire | | VA | Virtual Assistant | | VlM | Vision Language Models | | ViT | Visual Transformer | |

# Appendix B: References

[1] Alexandr Pihtovnicov, K. T. 2025. *AI Virtual Assistants in Healthcare: You Need It in 2025 | TechMagic*. https://​www.techmagic.co​/​blog/​ai-virtual-assistant-in-healthcare. Accessed 9 September 2025.

[2] Alsentzer, E., Murphy, J. R., Boag, W., Weng, W.-H., Di Jin, Naumann, T., and McDermott, M. B. A. 2019. *Publicly Available Clinical BERT Embeddings. DOI=*10.48550/arXiv.1904.03323.

[3] ANTHROPIC. 2025. *Model Context Protocol Specification*. Anthropic PBC.

[4] Arnaud, L. and others. 2025. Economic burden of systemic lupus erythematosus and lupus nephritis in France: a nationwide population-based study using the French medico-administrative (SNDS) claims database. *Joint Bone Spine* 92, 3, 105827.

[5] Bajwa, J., Munir, U., Nori, A., and Williams, B. 2021. Artificial intelligence in healthcare: transforming the practice of medicine. *Future Healthcare Journal* 8, 2, e188-e194.

[6] Baumgart, D. C. and Kvedar, J. C. 2025. Germany and Europe lead digital innovation and AI with collaborative health data use at continental level. *NPJ digital medicine* 8, 1, 215.

[7] Bharadwaj, P., Nicola, L., Breau-Brunel, M., Sensini, F., Tanova-Yotova, N., Atanasov, P., Lobig, F., and Blankenburg, M. 2024. Unlocking the Value: Quantifying the Return on Investment of Hospital Artificial Intelligence. *Journal of the American College of Radiology : JACR* 21, 10, 1677–1685.

[8] Bommasani, R. and others. *On the Opportunities and Risks of Foundation Models*. arXiv.

[9] Borges do Nascimento, Israel Júnior, Abdulazeem, H., Vasanthan, L. T., Martinez, E. Z., Zucoloto, M. L., Østengaard, L., Azzopardi-Muscat, N., Zapata, T., and Novillo-Ortiz, D. 2023. Barriers and facilitators to utilizing digital health technologies by healthcare professionals. *npj Digit. Med.* 6, 1, 161.

[10] Botelho, J. and others. 2022. Economic burden of periodontitis in the United States and Europe: An updated estimation. *Journal of periodontology* 93, 3, 373–379.

[11] Bowling, F. and Badrick, T. 2023. Methods for determining clinical utility. *Clinical biochemistry* 121-122, 110674.

[12] Breidenbach, M. and others. Development of a flexible and interoperable architecture to customize clinical solutions targeting the care of multimorbid patients. In *DSAI 2022*, 12–17. DOI=10.1145/3563137.3563157.

[13] Catamco, E. 2024. *Improving Cost-Efficiency With Healthcare Virtual Assistant*. https://​medcoresolutions.com​/​improving-cost-efficiency-with-healthcare-virtual-assistant/​. Accessed 9 September 2025.

[14] Chen, Y.-J., Albarqawi, A., and Chen, C.-S. 2025. *Reinforcing Clinical Decision Support through Multi-Agent Systems and Ethical AI Governance. DOI=*10.48550/arXiv.2504.03699.

[15] Chen, Y.-J., Albarqawi, A., and Chen, C.-S. 2025. *Reinforcing Clinical Decision Support through Multi-Agent Systems and Ethical AI Governance*.

[16] Coen, E. and others. 2025. Chatbot for the Return of Positive Genetic Screening Results for Hereditary Cancer Syndromes: Prompt Engineering Project. *JMIR cancer* 11, e65848.

[17] 2025. *Compliance Challenges at the Intersection between AI & GDPR in 2025*. https://​secureprivacy.ai​/​blog/​ai-gdpr-compliance-challenges-2025. Accessed 9 September 2025.

[18] DARE UK Delivery Team. 2024. *Federated Architecture Blueprint*. Technical Report. DARE UK. DOI=10.5281/zenodo.14192786.

[19] Deloitte Center for Health Solutions. 2024. *Building and maintaining health care consumers’ trust in generative AI*.

[20] Dyba, T. and others. 2021. The European cancer burden in 2020: Incidence and mortality estimates for 40 countries and 25 major cancers. *European journal of cancer (Oxford, England : 1990)* 157, 308–347.

[21] El Arab, R. A. and Al Moosa, O. A. 2025. Systematic review of cost effectiveness and budget impact of artificial intelligence in healthcare. *npj Digit. Med.* 8, 1, 548.

[22] European Commission - Joint Research Centre. *Prostate Cancer Factsheet*.

[23] European Parliament. 2025. *REGULATION (EU) 2025/327 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 11 February 2025 on the European Health Data Space*. *2025/327*.

[24] European Parliament and Council. 2017. *Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices*. http://​data.europa.eu​/​eli/​reg/​2017/​745/​2025-01-10.

[25] European Parliament and Council. 2024. *Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024, Artificial Intelligence Act* L 1689. Publications Office of the European Union, Luxembourg. *Official Journal of the European Union* L 1689. http://​data.europa.eu​/​eli/​reg/​2024/​1689/​oj.

[26] European Parliament and Council of the European Union. 2016. *Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)* L 119 L 119. http://​data.europa.eu​/​eli/​reg/​2016/​679/​oj.

[27] European Parliamentary Research Service. 2023. *European Health Data Space – Briefing*.

[28] eurostat. 2025. *Healthcare personnel statistics - physicians*. https://​ec.europa.eu​/​eurostat/​statistics-explained/​index.php?title=Healthcare\_personnel\_statistics\_-\_physicians. Accessed 9 September 2025.

[29] Fernandes, F. A., Chaltikyan, G., Adib, K., Caton-Peters, H., and Novillo-Ortiz, D. 2024. The role of governance in the digital transformation of healthcare: Results of a survey in the WHO Europe Region. *International Journal of Medical Informatics* 189, 105510.

[30] Fourcade, R. O., Benedict, A., Black, L. K., Stokes, M. E., Alcaraz, A., and Castro, R. 2010. Treatment costs of prostate cancer in the first year after diagnosis: a short-term cost of illness study for France, Germany, Italy, Spain and the UK. *BJU international* 105, 1, 49–56.

[31] Gangavarapu, A. and Gangavarapu, A. 2024. *IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery. DOI=*10.48550/arXiv.2410.12868.

[32] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Wang, M., and Wang, H. 2023. *Retrieval-Augmented Generation for Large Language Models: A Survey. DOI=*10.48550/arXiv.2312.10997.

[33] Ghassemi, M., Oakden-Rayner, L., and Beam, A. L. 2021. The false hope of current approaches to explainable artificial intelligence in health care. *The Lancet. Digital health* 3, 11, e745-e750.

[34] 2023. Global, regional, and national burden of rheumatoid arthritis, 1990-2020, and projections to 2050: a systematic analysis of the Global Burden of Disease Study 2021. *The Lancet. Rheumatology* 5, 10, e594-e610.

[35] Guluzade, A. and others. 2025. ELMTEX: Fine-Tuning LLMs for Structured Clinical Information Extraction. A Case Study on Clinical Reports. In *Artificial Intelligence in Medicine*, R. Bellazzi and others, Eds. Lecture Notes in Computer Science. Springer Nature Switzerland, Cham, 181–185. DOI=10.1007/978-3-031-95841-0\_34.

[36] Hamiti, F. and others. A Data Space infrastructure supporting the integration of clinical data nodes and cancer registries to improve personalized medicine. In *DSAI 2024*, 252–259. DOI=10.1145/3696593.3696627.

[37] Hashim, N. T., Babiker, R., Padmanabhan, V., Ahmed, A. T., Chaitanya, N. C. S. K., Mohammed, R., Priya, S. P., Ahmed, A., El Bahra, S., Islam, M. S., Gismalla, B. G., and Rahman, M. M. 2025. The Global Burden of Periodontal Disease: A Narrative Review on Unveiling Socioeconomic and Health Challenges. *International journal of environmental research and public health* 22, 4.

[38] Hinostroza Fuentes, V. G., Karim, H. A., Tan, M. J. T., and AlDahoul, N. 2025. AI with agency: a vision for adaptive, efficient, and ethical healthcare. *Frontiers in digital health* 7, 1600216.

[39] Hsieh, P.-H. and others. 2020. Economic burden of rheumatoid arthritis: a systematic review of literature in biologic era. *Annals of the Rheumatic Diseases* 79, 6, 771–777.

[40] Huang, B., Huang, H., Zhang, S., Zhang, D., Shi, Q., Liu, J., and Guo, J. 2022. Artificial intelligence in pancreatic cancer. *Theranostics* 12, 16, 6931–6954.

[41] Huang, Y. and others. 2024. Position: TrustLLM: Trustworthiness in Large Language Models. In *Proceedings of the 41st International Conference on Machine Learning*. Proceedings of Machine Learning Research. PMLR, 20166–20270.

[42] InterSystems Corporation. 2025. *Healthcare Interoperability*. https://​www.intersystems.com​/​use-cases/​healthcare-interoperability/​. Accessed 9 September 2025.

[43] J. Scott MARCUS and others. 2022. *The European Health Data Space*. Policy Department for Economic, Scientific and Quality of Life Policies, European Parliament, Luxembourg. DOI=10.2861/88936.

[44] James, N. D. and others. 2024. The Lancet Commission on prostate cancer: planning for the surge in cases. *Lancet (London, England)* 403, 10437, 1683–1722.

[45] James Gillespie, B. G. 2025. *European Healthcare Workforce | EuropeanHHM Healthcare Management*. https://​www.europeanhhm.com​/​healthcare-management/​impact-european-healthcare-workforce. Accessed 9 September 2025.

[46] Joint Research Centre (JRC), International Agency for Research on Cancer (IARC) and European Cancer Information System. 2023. *New Cancer Cases and Cancer Deaths on the Rise in the EU 2022*.

[47] Karunanayake, N. 2025. Next-generation agentic AI for transforming healthcare. *Informatics and Health* 2, 2, 73–83.

[48] Klementi, T., Piho, G., and Ross, P. 2024. A reference architecture for personal health data spaces using decentralized content-addressable storage networks. *Frontiers in medicine* 11, 1411013.

[49] Lakhan, S. E. 2025. The Agentic Era: Why Biopharma Must Embrace Artificial Intelligence That Acts, Not Just Informs. *Cureus* 17, 5, e83390.

[50] Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C. H., and Kang, J. 2020. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. *Bioinformatics (Oxford, England)* 36, 4, 1234–1240.

[51] Li, C., Wong, C., Zhang, S., Usuyama, N., Liu, H., Yang, J., Naumann, T., Poon, H., and Gao, J. 2023. *LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day. DOI=*10.48550/arXiv.2306.00890.

[52] Li, J., Lai, Y., Li, W., Ren, J., Zhang, M., Kang, X., Wang, S., Li, P., Zhang, Y.-Q., Ma, W., and Liu, Y. 2024. *Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents. DOI=*10.48550/arXiv.2405.02957.

[53] Li, Z. and others. 2025. A Survey of State of the Art Large Vision Language Models: Alignment, Benchmark, Evaluations and Challenges.

[54] Liu, J. 2024. ChatGPT: perspectives from human-computer interaction and psychology. *Frontiers in artificial intelligence* 7, 1418869.

[55] Lokmic-Tomkins, Z., Davies, S., Block, L. J., Cochrane, L., Dorin, A., Gerich, H. von, Lozada-Perezmitre, E., Reid, L., and Peltonen, L.-M. 2022. Assessing the carbon footprint of digital health interventions: a scoping review. *Journal of the American Medical Informatics Association : JAMIA* 29, 12, 2128–2139.

[56] López, L. J. L. and others. 2025. *Uncertainty Quantification for Machine Learning in Healthcare: A Survey. DOI=*10.48550/arXiv.2505.02874.

[57] ltd, M. D. F. 2025. *Europe Ai In Healthcare Market Size, Share & Growth, 2033*. https://​www.marketdataforecast.com​/​market-reports/​europe-ai-in-healthcare-market. Accessed 9 September 2025.

[58] Luengo-Fernandez, R., Leal, J., Gray, A., and Sullivan, R. 2013. Economic burden of cancer across the European Union: a population-based cost analysis. *The Lancet Oncology* 14, 12, 1165–1174.

[59] Luengo-Fernandez, R. and others. 2013. Economic burden of cancer across the European Union: a population-based cost analysis. *The Lancet Oncology* 14, 12, 1165–1174.

[60] Ma, Y. and others. 2025. Global, regional & national burden of rheumatoid arthritis from 1990 to 2021, with projections of incidence to 2050: a systematic & comprehensive analysis of the Global Burden of Disease study 2021. *Biomarker research* 13, 1, 47.

[61] Mandl, K. D., Gottlieb, D., and Mandel, J. C. 2024. Integration of AI in healthcare requires an interoperable digital data ecosystem. *Nature medicine* 30, 3, 631–634.

[62] Marta Iraola Iribarren & Paula Soler. 2024. *The EU health paradox: Shortages with surging staff numbers*. https://​www.euronews.com​/​health/​2024/​12/​04/​the-eu-health-paradox-shortages-with-surging-staff-numbers. Accessed 9 September 2025.

[63] Massimiliano Masnada, Giulia Mariuz, Giacomo Bertelli, and Alessandro Bacchilega. 2025. *EU moves closer to a unified digital health system with the European Health Data Space Regulation (EHDS)*. https://​www.hoganlovells.com​/​en/​publications/​eu-moves-closer-to-a-unified-digital-health-system-with-the-european-health-data-space-regulation-ehds. Accessed 9 September 2025.

[64] Milella, F. and Bandini, S. 2024. Fostering Artificial Intelligence-based supports for informal caregivers: a systematic review of the literature. *IA* 18, 1, 67–87.

[65] Mishra, S., Chaudhury, P., Tripathy, H. K., Sahoo, K. S., Jhanjhi, N. Z., Hassan Elnour, A. A., and Abdelmaboud, A. 2024. Enhancing health care through medical cognitive virtual agents. *Digital health* 10, 20552076241256732.

[66] Mitchell, S. 2025. *UK leads Europe in AI investment with Gen AI boosts & big savings*. https://​itbrief.co.uk​/​story/​uk-leads-europe-in-ai-investment-with-gen-ai-boosts-big-savings. Accessed 9 September 2025.

[67] Moustafa Laymouna, Yuanchao Ma, David Lessard, Tibor Schuster, Kim Engler, and Bertrand Lebouché. 2024. Roles, Users, Benefits, and Limitations of Chatbots in Health Care: Rapid Review 26, e56930.

[68] 2025. *National digital healthcare adoption: Global best practices | McKinsey*. https://​www.mckinsey.com.br​/​industries/​healthcare/​our-insights/​scaling-national-e-health-best-practices-from-around-the-world. Accessed 9 September 2025.

[69] Olufunke A. Akande. 2023. ARCHITECTING DECENTRALIZED AI FRAMEWORKS FOR MULTI-MODAL HEALTH DATA FUSION TO ADVANCE EQUITABLE AND PERSONALIZED MEDICINE.

[70] Philips. 2025. *Digital transformation in healthcare: seven key success factors | Philips*. https://​www.philips.com​/​a-w/​about/​news/​archive/​features/​2022/​20220413-seven-key-success-factors-for-digital-transformation-in-healthcare.html. Accessed 9 September 2025.

[71] Polisetty, S. M. 2025. AI-Driven Diagnosis and Treatment Recommendation in Healthcare: A Hybrid Deep Learning Framework. *Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol* 11, 1, 2351–2359.

[72] Practolytics. 2025. *How Virtual Assistants Enhance Patient Engagement and Satisfaction*. https://​practolytics.com​/​blog/​how-virtual-assistants-enhance-patient-engagement-and-satisfaction/​. Accessed 9 September 2025.

[73] Proietto Salanitri, F., Viriri, S., Bağcı, U., Tiwari, P., Gong, B., Spampinato, C., Palazzo, S., Bellitto, G., Zlatintsi, N., Filntisis, P., Lee, C. S., and Lee, A. Y., Eds. 2025. *Artificial Intelligence in Pancreatic Disease Detection and Diagnosis, and Personalized Incremental Learning in Medicine*. Lecture Notes in Computer Science 15197. Springer Nature Switzerland, Cham.

[74] Public Health. 2025. *European Health Data Space Regulation (EHDS)*. https://​health.ec.europa.eu​/​ehealth-digital-health-and-care/​european-health-data-space-regulation-ehds\_en. Accessed 9 September 2025.

[75] PwC EU Services EEIG and Open Evidence. 2025. *Study on the deployment of AI in healthcare: Final report* EW-01-25-076-EN-N. European Commission, Directorate General For Health and Food Safety, Luxembourg. DOI=10.2875/2169577.

[76] Qiu, J., Lam, K., Li, G., Acharya, A., Wong, T. Y., Darzi, A., Yuan, W., and Topol, E. J. 2024. LLM-based agentic systems in medicine and healthcare. *Nat Mach Intell* 6, 12, 1418–1420.

[77] Raab, R. and others. 2023. Federated electronic health records for the European Health Data Space. *The Lancet. Digital health* 5, 11, e840-e847.

[78] Rosenbacke, R., Melhus, Å., McKee, M., and Stuckler, D. 2024. How Explainable Artificial Intelligence Can Increase or Decrease Clinicians' Trust in AI Applications in Health Care: Systematic Review. *JMIR AI* 3, e53207.

[79] Satturwar, S. and Parwani, A. V. 2024. Artificial Intelligence-Enabled Prostate Cancer Diagnosis and Prognosis: Current State and Future Implications. *Advances in anatomic pathology* 31, 2, 136–144.

[80] Schafer, E. J., Laversanne, M., Sung, H., Soerjomataram, I., Briganti, A., Dahut, W., Bray, F., and Jemal, A. 2025. Recent Patterns and Trends in Global Prostate Cancer Incidence and Mortality: An Update. *European urology* 87, 3, 302–313.

[81] Sellergren, A. and others. 2025. *MedGemma Technical Report. DOI=*10.48550/arXiv.2507.05201.

[82] Shaping Europe’s digital future. 2025. *State of the Digital Decade 2025 report*. https://​digital-strategy.ec.europa.eu​/​en/​library/​state-digital-decade-2025-report. Accessed 9 September 2025.

[83] Simon, B. D., Ozyoruk, K. B., Gelikman, D. G., Harmon, S. A., and Türkbey, B. 2025. The future of multimodal artificial intelligence models for integrating imaging and clinical metadata: a narrative review. *Diagnostic and interventional radiology (Ankara, Turkey)* 31, 4, 303–312.

[84] Singhal, K. and others. 2023. Large language models encode clinical knowledge. *Nature* 620, 7972, 172–180.

[85] Sohail, S. S. 2024. A Promising Start and Not a Panacea: ChatGPT's Early Impact and Potential in Medical Science and Biomedical Engineering Research. *Annals of biomedical engineering* 52, 5, 1131–1135.

[86] Srivastava, A. and Panda, S. 2024. *A Formal Framework for Assessing and Mitigating Emergent Security Risks in Generative AI Models: Bridging Theory and Dynamic Risk Mitigation*.

[87] Statista. 2025. *HCPs' trust in using AI in healthcare Europe 2024| Statista*. https://​www.statista.com​/​statistics/​1558690/​hcps-trust-in-using-ai-in-healthcare-europe/​. Accessed 9 September 2025.

[88] Stefano Santangelo. 2025. *How to make the European Health Data Space a reality? (Guest blog)*. https://​www.efpia.eu​/​news-events/​the-efpia-view/​blog-articles/​how-to-make-the-european-health-data-space-a-reality/​. Accessed 9 September 2025.

[89] Supriyono, Wibawa, A. P., Suyono, and Kurniawan, F. 2024. Advancements in natural language processing: Implications, challenges, and future directions. *Telematics and Informatics Reports* 16, 100173.

[90] Tabassi, E. 2023. *Artificial Intelligence Risk Management Framework (AI RMF 1.0)*, Gaithersburg, MD. DOI=10.6028/NIST.AI.100-1.

[91] Tam, T. o. 2024. A framework for human evaluation of large language models in healthcare derived from literature review. *NPJ digital medicine* 7, 1, 258.

[92] 2025. *The Transformative Impact of Generative AI in Telehealth: Advancing Remote Healthcare Delivery*. https://​www.makebot.ai​/​blog-en/​the-transformative-impact-of-generative-ai-in-telehealth-advancing-remote-healthcare-delivery. Accessed 9 September 2025.

[93] Todericiu, I. A. 2025. Virtual Assistants: A Review of the Next Frontier in AI Interaction. *Acta Univ. Sapientiae Inform.* 17, 1.

[94] Tonetti, M. S. and others. 2017. Impact of the global burden of periodontal diseases on health, nutrition and wellbeing of mankind: A call for global action. *Journal of clinical periodontology* 44, 5, 456–462.

[95] Trindade, D. and others. 2023. Prevalence of periodontitis in dentate people between 2011 and 2020: A systematic review and meta-analysis of epidemiological studies. *Journal of clinical periodontology* 50, 5, 604–626.

[96] Turchin, A., Masharsky, S., and Zitnik, M. 2023. Comparison of BERT implementations for natural language processing of narrative medical documents. *Informatics in Medicine Unlocked* 36, 101139.

[97] van der Vegt, A. H. and others. 2023. Implementation frameworks for end-to-end clinical AI: derivation of the SALIENT framework. *Journal of the American Medical Informatics Association : JAMIA* 30, 9, 1503–1515.

[98] Vasey, B. and others. 2022. Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI. *Nature medicine* 28, 5, 924–933.

[99] Wang, W., Ma, Z., Wang, Z., Wu, C., Ji, J., Chen, W., Li, X., and Yuan, Y. 2025. *A Survey of LLM-based Agents in Medicine: How far are we from Baymax? DOI=*10.48550/arXiv.2502.11211.

[100] Wiggers, K. 2024. *Generative AI is coming for healthcare, and not everyone’s thrilled*. https://​techcrunch.com​/​2024/​04/​14/​generative-ai-is-coming-for-healthcare-and-not-everyones-thrilled/​. Accessed 12 August 2025.

[101] Yan, Z. and others. 2024. Understanding older people's voice interactions with smart voice assistants: a new modified rule-based natural language processing model with human input. *Frontiers in digital health* 6, 1329910.

[102] Yang, X. and others. 2022. *GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records. DOI=*10.48550/arXiv.2203.03540.

[103] Yin, S., Fu, C., Zhao, S., Li, K., Sun, X., Xu, T., and Chen, E. 2024. A survey on multimodal large language models. *National science review* 11, 12, nwae403.

[104] Zhang, F., Kreuter, D., Chen, Y., Dittmer, S., Tull, S., Shadbahr, T., Preller, J., Rudd, J. H. F., Aston, J. A. D., Schönlieb, C.-B., Gleadall, N., and Roberts, M. 2024. Recent methodological advances in federated learning for healthcare. *Patterns (New York, N.Y.)* 5, 6, 101006.

[105] Zhang, X., Wang, X., Wu, J., Wang, M., Hu, B., Qu, H., Zhang, J., and Li, Q. 2024. The global burden of periodontal diseases in 204 countries and territories from 1990 to 2019. *Oral diseases* 30, 2, 754–768.

[106] Zheng, Q. and others. 2022. UX Research on Conversational Human-AI Interaction: A Literature Review of the ACM Digital Library. In *CHI Conference on Human Factors in Computing Systems*. ACM, New York, NY, USA, 1–24. DOI=10.1145/3491102.3501855.

[107] Zou, J. and Topol, E. J. 2025. The rise of agentic AI teammates in medicine. *Lancet (London, England)* 405, 10477, 457.

1. e.g., “I understand the plan my clinician presented me today.” [↑](#footnote-ref-2)
2. **Likelihood**: Unlikely / Possible / Likely - **Severity**: Low / Medium / High [↑](#footnote-ref-3)